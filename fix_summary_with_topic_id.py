#!/usr/bin/env python3
"""
ä½¿ç”¨topic_idå…³è”ä¿®å¤summary - æ­£ç¡®ç‰ˆæœ¬
å§‹ç»ˆä½¿ç”¨å¤§æ¨¡å‹æ€»ç»“ï¼Œrelated_tweetsä½¿ç”¨æ¨æ–‡ID
"""
import sys
import os
from datetime import datetime

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.database.topic_dao import topic_dao
from src.database.tweet_dao import tweet_dao
from src.api.chatgpt_client import chatgpt_client
from src.utils.logger import setup_logger


def get_topic_tweets_by_id(topic_id: str):
    """é€šè¿‡topic_idç›´æ¥è·å–å…³è”çš„æ¨æ–‡"""
    try:
        db_manager = tweet_dao.db_manager
        
        sql = """
        SELECT id_str, kol_id, full_text, created_at,
               favorite_count, retweet_count, reply_count, view_count
        FROM twitter_tweet
        WHERE topic_id = %s
        ORDER BY created_at DESC
        """
        
        tweets = db_manager.execute_query(sql, [topic_id])
        return tweets if tweets else []
        
    except Exception as e:
        print(f"âŒ è·å–topicæ¨æ–‡å¤±è´¥: {e}")
        return []


def generate_ai_summary_always(topic_data, tweets):
    """å§‹ç»ˆä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆsummaryï¼ŒæŒ‰ç…§æŒ‡å®šæ ¼å¼"""
    try:
        if not tweets:
            print(f"   âš ï¸ æ²¡æœ‰å…³è”æ¨æ–‡ï¼Œæ— æ³•ç”Ÿæˆsummary")
            return None
        
        topic_name = topic_data.get('topic_name', topic_data.get('topic_id', ''))
        
        # æ„å»ºå®Œæ•´çš„è¯é¢˜æ•°æ®
        enhanced_topic_data = {
            'topic_id': topic_data.get('topic_id', ''),
            'topic_name': topic_name,
            'category': 'cryptocurrency',
            'key_entities': topic_name.split(),
            'timestamp': datetime.now().isoformat(),
            'brief': topic_data.get('brief', f"{topic_name} ç›¸å…³è®¨è®º"),
            'related_tweets': []
        }
        
        # æ„å»ºæ¨æ–‡æ•°æ®
        for tweet in tweets:
            tweet_data = {
                'id_str': tweet['id_str'],
                'kol_id': tweet.get('kol_id', ''),
                'full_text': tweet['full_text']
            }
            enhanced_topic_data['related_tweets'].append(tweet_data)
        
        kol_count = sum(1 for t in tweets if t.get('kol_id'))
        print(f"   ğŸ“Š æ¨æ–‡è¯¦æƒ…: æ€»è®¡{len(tweets)}æ¡ï¼ŒKOLæ¨æ–‡{kol_count}æ¡")
        
        # å§‹ç»ˆä½¿ç”¨KOLè§‚ç‚¹åˆ†ææ–¹æ³•ï¼ˆå¤§æ¨¡å‹ï¼‰
        summary = chatgpt_client.generate_kol_consensus_summary(enhanced_topic_data)
        
        if summary:
            print(f"   âœ… AIæ€»ç»“ç”ŸæˆæˆåŠŸ (é•¿åº¦: {len(summary)})")
            
            # éªŒè¯å¹¶ä¿®æ­£æ ¼å¼
            import json
            try:
                parsed = json.loads(summary)
                
                # ç¡®ä¿related_tweetsä½¿ç”¨æ¨æ–‡IDè€Œä¸æ˜¯æ¨æ–‡å†…å®¹
                if 'summary' in parsed:
                    for viewpoint in parsed['summary']:
                        if 'related_tweets' in viewpoint:
                            # å¦‚æœrelated_tweetsåŒ…å«é•¿æ–‡æœ¬ï¼Œæ›¿æ¢ä¸ºID
                            tweet_refs = viewpoint['related_tweets']
                            tweet_ids = []
                            
                            for ref in tweet_refs:
                                if isinstance(ref, str):
                                    if len(ref) > 50:  # é•¿æ–‡æœ¬ï¼ŒæŸ¥æ‰¾å¯¹åº”çš„æ¨æ–‡ID
                                        # æŸ¥æ‰¾åŒ…å«æ­¤æ–‡æœ¬çš„æ¨æ–‡ID
                                        for tweet in tweets:
                                            if ref[:30] in tweet['full_text']:
                                                tweet_ids.append(tweet['id_str'])
                                                break
                                    else:
                                        tweet_ids.append(ref)  # å·²ç»æ˜¯IDæˆ–çŸ­å¼•ç”¨
                            
                            viewpoint['related_tweets'] = tweet_ids[:3]  # é™åˆ¶æ•°é‡
                
                # é‡æ–°åºåˆ—åŒ–
                summary = json.dumps(parsed, ensure_ascii=False)
                print(f"   âœ… æ ¼å¼éªŒè¯å¹¶ä¿®æ­£å®Œæˆ")
                
            except json.JSONDecodeError as e:
                print(f"   âš ï¸ JSONæ ¼å¼é—®é¢˜: {e}")
                return summary  # è¿”å›åŸå§‹ç»“æœ
                
            return summary
        else:
            print(f"   âŒ AIæ€»ç»“ç”Ÿæˆå¤±è´¥")
            return None
            
    except Exception as e:
        print(f"âŒ ç”ŸæˆAIæ€»ç»“å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None


def fix_topic_summary_correct(topic_data):
    """ä½¿ç”¨æ­£ç¡®çš„é€»è¾‘ä¿®å¤å•ä¸ªè¯é¢˜çš„summary"""
    try:
        topic_id = topic_data['topic_id']
        topic_name = topic_data['topic_name']
        
        print(f"ğŸ”§ å¤„ç†è¯é¢˜: {topic_name}")
        print(f"   Topic ID: {topic_id}")
        
        # é€šè¿‡topic_idç›´æ¥è·å–å…³è”æ¨æ–‡
        tweets = get_topic_tweets_by_id(topic_id)
        
        if not tweets:
            print(f"   âŒ æ²¡æœ‰æ‰¾åˆ°å…³è”æ¨æ–‡ï¼Œè·³è¿‡")
            return False
        
        # å§‹ç»ˆä½¿ç”¨AIç”Ÿæˆsummary
        summary = generate_ai_summary_always(topic_data, tweets)
        
        if summary:
            # æ›´æ–°æ•°æ®åº“
            db_manager = topic_dao.db_manager
            update_sql = """
            UPDATE topics 
            SET summary = %s, update_time = %s 
            WHERE topic_id = %s
            """
            
            result = db_manager.execute_update(update_sql, [
                summary, 
                datetime.now(), 
                topic_id
            ])
            
            if result:
                print(f"   âœ… æ•°æ®åº“æ›´æ–°æˆåŠŸ")
                return True
            else:
                print(f"   âŒ æ•°æ®åº“æ›´æ–°å¤±è´¥")
                return False
        else:
            print(f"   âŒ summaryç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ å¤„ç†è¯é¢˜å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•° - ä¿®å¤æœ‰æ¨æ–‡å…³è”çš„topics"""
    setup_logger()
    
    print("ğŸš€ ä½¿ç”¨æ­£ç¡®é€»è¾‘ä¿®å¤topicsè¡¨summary")
    print("=" * 60)
    
    try:
        db_manager = topic_dao.db_manager
        
        # è·å–æœ‰å…³è”æ¨æ–‡ä½†summaryä¸ºnullçš„è¯é¢˜
        sql = """
        SELECT DISTINCT t.topic_id, t.topic_name, t.brief, t.created_at
        FROM topics t
        JOIN twitter_tweet tw ON t.topic_id = tw.topic_id
        WHERE t.summary IS NULL
        ORDER BY t.created_at DESC
        LIMIT 15
        """
        
        topics_to_fix = db_manager.execute_query(sql)
        
        if not topics_to_fix:
            print("âœ… æ²¡æœ‰å‘ç°éœ€è¦ä¿®å¤çš„è¯é¢˜ï¼ˆæœ‰æ¨æ–‡å…³è”ä½†æ— summaryï¼‰")
            return
        
        print(f"ğŸ“Š å‘ç° {len(topics_to_fix)} ä¸ªæœ‰æ¨æ–‡å…³è”ä½†æ— summaryçš„è¯é¢˜")
        
        # æ‰¹é‡å¤„ç†
        success_count = 0
        
        for i, topic in enumerate(topics_to_fix, 1):
            print(f"\nå¤„ç†è¿›åº¦: {i}/{len(topics_to_fix)}")
            
            if fix_topic_summary_correct(topic):
                success_count += 1
        
        # è¾“å‡ºç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ¯ ä¿®å¤ç»“æœç»Ÿè®¡:")
        print(f"   æ€»å¤„ç†æ•°é‡: {len(topics_to_fix)}")
        print(f"   ä¿®å¤æˆåŠŸ: {success_count}")
        print(f"   æˆåŠŸç‡: {success_count/len(topics_to_fix)*100:.1f}%")
        
        if success_count > 0:
            print(f"\nâœ… æˆåŠŸä¸º {success_count} ä¸ªè¯é¢˜ç”Ÿæˆäº†AI summary")
            print(f"âœ… æ‰€æœ‰summaryéƒ½ä½¿ç”¨äº†å¤§æ¨¡å‹ç”Ÿæˆ")
            print(f"âœ… related_tweetså­—æ®µåŒ…å«æ­£ç¡®çš„æ¨æ–‡ID")
        
    except Exception as e:
        print(f"âŒ ä¿®å¤è¿‡ç¨‹å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()