#!/usr/bin/env python3
"""
æ‰¹å¤„ç†ä¼˜åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•æ–°çš„æ™ºèƒ½æ‰¹å¤„ç†å’ŒtokenèŠ‚çœæ•ˆæœ
"""

import sys
import time
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from src.api.chatgpt_client import chatgpt_client
from src.topic_engine import topic_engine
from src.database.tweet_dao import tweet_dao
from src.utils.logger import get_logger

class BatchOptimizationTester:
    """æ‰¹å¤„ç†ä¼˜åŒ–æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.logger = get_logger(__name__)
        self.chatgpt_client = chatgpt_client
        self.topic_engine = topic_engine
        
    def test_batch_topic_extraction(self, tweet_count: int = 20) -> Dict[str, Any]:
        """
        æµ‹è¯•æ‰¹é‡è¯é¢˜æå–æ•ˆæœ
        
        Args:
            tweet_count: æµ‹è¯•æ¨æ–‡æ•°é‡
            
        Returns:
            æµ‹è¯•ç»“æœç»Ÿè®¡
        """
        self.logger.info(f"å¼€å§‹æµ‹è¯•æ‰¹é‡è¯é¢˜æå–ï¼Œæ¨æ–‡æ•°é‡: {tweet_count}")
        
        # è·å–æµ‹è¯•æ¨æ–‡
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)
        
        tweets = tweet_dao.get_tweets_by_date_range(
            start_date=start_time,
            end_date=end_time,
            limit=tweet_count
        )
        
        if not tweets:
            self.logger.error("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ¨æ–‡")
            return {}
        
        self.logger.info(f"è·å–åˆ° {len(tweets)} æ¡æµ‹è¯•æ¨æ–‡")
        
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.chatgpt_client.request_count = 0
        self.chatgpt_client.success_count = 0
        self.chatgpt_client.error_count = 0
        
        # æµ‹è¯•1ï¼šä¼ ç»Ÿé€ä¸ªå¤„ç†
        self.logger.info("=" * 50)
        self.logger.info("æµ‹è¯•1: ä¼ ç»Ÿé€ä¸ªå¤„ç†")
        
        start_time_traditional = time.time()
        traditional_results = []
        traditional_api_calls = 0
        
        for tweet in tweets[:10]:  # æµ‹è¯•å‰10æ¡
            result = self.chatgpt_client.extract_topic_from_tweet(tweet.full_text)
            traditional_results.append(result)
            traditional_api_calls += 1
        
        traditional_duration = time.time() - start_time_traditional
        traditional_requests = self.chatgpt_client.request_count
        
        self.logger.info(f"ä¼ ç»Ÿæ–¹å¼å®Œæˆï¼Œè€—æ—¶: {traditional_duration:.2f}ç§’")
        self.logger.info(f"APIè°ƒç”¨æ¬¡æ•°: {traditional_requests}")
        
        # é‡ç½®ç»Ÿè®¡
        self.chatgpt_client.request_count = 0
        
        # æµ‹è¯•2ï¼šæ–°çš„æ‰¹é‡å¤„ç†
        self.logger.info("=" * 50)
        self.logger.info("æµ‹è¯•2: æ–°çš„æ™ºèƒ½æ‰¹é‡å¤„ç†")
        
        start_time_batch = time.time()
        tweet_contents = [tweet.full_text for tweet in tweets[:10]]
        batch_results = self.chatgpt_client.batch_extract_topics_from_tweets(tweet_contents)
        
        batch_duration = time.time() - start_time_batch
        batch_requests = self.chatgpt_client.request_count
        
        self.logger.info(f"æ‰¹é‡æ–¹å¼å®Œæˆï¼Œè€—æ—¶: {batch_duration:.2f}ç§’")
        self.logger.info(f"APIè°ƒç”¨æ¬¡æ•°: {batch_requests}")
        
        # è®¡ç®—ä¼˜åŒ–æ•ˆæœ
        time_saved = traditional_duration - batch_duration
        time_saved_percent = (time_saved / traditional_duration) * 100 if traditional_duration > 0 else 0
        
        api_calls_saved = traditional_requests - batch_requests
        api_calls_saved_percent = (api_calls_saved / traditional_requests) * 100 if traditional_requests > 0 else 0
        
        results = {
            'test_tweet_count': 10,
            'traditional': {
                'duration_seconds': traditional_duration,
                'api_calls': traditional_requests,
                'results_count': len([r for r in traditional_results if r])
            },
            'batch_optimized': {
                'duration_seconds': batch_duration,
                'api_calls': batch_requests,
                'results_count': len([r for r in batch_results if r])
            },
            'optimization_effect': {
                'time_saved_seconds': time_saved,
                'time_saved_percent': time_saved_percent,
                'api_calls_saved': api_calls_saved,
                'api_calls_saved_percent': api_calls_saved_percent
            }
        }
        
        self.logger.info("=" * 50)
        self.logger.info("ä¼˜åŒ–æ•ˆæœæ€»ç»“:")
        self.logger.info(f"æ—¶é—´èŠ‚çœ: {time_saved:.2f}ç§’ ({time_saved_percent:.1f}%)")
        self.logger.info(f"APIè°ƒç”¨èŠ‚çœ: {api_calls_saved} æ¬¡ ({api_calls_saved_percent:.1f}%)")
        
        return results
    
    def test_content_filtering(self, tweet_count: int = 50) -> Dict[str, Any]:
        """
        æµ‹è¯•å†…å®¹é¢„ç­›é€‰æ•ˆæœ
        
        Args:
            tweet_count: æµ‹è¯•æ¨æ–‡æ•°é‡
            
        Returns:
            ç­›é€‰æ•ˆæœç»Ÿè®¡
        """
        self.logger.info(f"å¼€å§‹æµ‹è¯•å†…å®¹é¢„ç­›é€‰ï¼Œæ¨æ–‡æ•°é‡: {tweet_count}")
        
        # è·å–æµ‹è¯•æ¨æ–‡
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=48)
        
        tweets = tweet_dao.get_tweets_by_date_range(
            start_date=start_time,
            end_date=end_time,
            limit=tweet_count
        )
        
        if not tweets:
            self.logger.error("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ¨æ–‡")
            return {}
        
        original_count = len(tweets)
        filtered_tweets = self.topic_engine._filter_high_quality_tweets(tweets)
        filtered_count = len(filtered_tweets)
        
        filtered_out_count = original_count - filtered_count
        filter_rate = (filtered_out_count / original_count) * 100 if original_count > 0 else 0
        
        results = {
            'original_tweet_count': original_count,
            'filtered_tweet_count': filtered_count,
            'filtered_out_count': filtered_out_count,
            'filter_rate_percent': filter_rate,
            'potential_api_calls_saved': filtered_out_count
        }
        
        self.logger.info("=" * 50)
        self.logger.info("å†…å®¹ç­›é€‰æ•ˆæœ:")
        self.logger.info(f"åŸå§‹æ¨æ–‡æ•°: {original_count}")
        self.logger.info(f"ç­›é€‰åæ¨æ–‡æ•°: {filtered_count}")
        self.logger.info(f"è¿‡æ»¤æ‰æ¨æ–‡æ•°: {filtered_out_count}")
        self.logger.info(f"è¿‡æ»¤ç‡: {filter_rate:.1f}%")
        self.logger.info(f"æ½œåœ¨èŠ‚çœAPIè°ƒç”¨: {filtered_out_count} æ¬¡")
        
        return results
    
    def test_cache_effectiveness(self, test_rounds: int = 3) -> Dict[str, Any]:
        """
        æµ‹è¯•å“åº”ç¼“å­˜æ•ˆæœ
        
        Args:
            test_rounds: æµ‹è¯•è½®æ•°
            
        Returns:
            ç¼“å­˜æ•ˆæœç»Ÿè®¡
        """
        self.logger.info(f"å¼€å§‹æµ‹è¯•å“åº”ç¼“å­˜æ•ˆæœï¼Œæµ‹è¯•è½®æ•°: {test_rounds}")
        
        # å‡†å¤‡æµ‹è¯•å†…å®¹
        test_tweets = [
            "Bitcoin is breaking new highs today! ğŸš€ #BTC",
            "Ethereum 2.0 staking rewards are impressive",
            "DeFi protocols are revolutionizing finance",
            "NFT market showing signs of recovery",
            "Bitcoin price action looks bullish"
        ]
        
        # æ¸…ç©ºç¼“å­˜
        if hasattr(self.chatgpt_client, 'response_cache'):
            self.chatgpt_client.response_cache.clear()
        
        cache_hits = 0
        total_requests = 0
        
        for round_num in range(test_rounds):
            self.logger.info(f"æµ‹è¯•è½®æ¬¡ {round_num + 1}/{test_rounds}")
            
            # é‡ç½®è¯·æ±‚è®¡æ•°
            initial_requests = self.chatgpt_client.request_count
            
            # æ‰¹é‡å¤„ç†ç›¸åŒå†…å®¹
            results = self.chatgpt_client.batch_extract_topics_from_tweets(test_tweets)
            
            # è®¡ç®—å®é™…APIè¯·æ±‚æ•°
            actual_requests = self.chatgpt_client.request_count - initial_requests
            expected_requests = len(test_tweets) if round_num == 0 else 0  # ç¬¬ä¸€è½®éœ€è¦è¯·æ±‚ï¼Œåç»­è½®æ¬¡åº”è¯¥å…¨éƒ¨å‘½ä¸­ç¼“å­˜
            
            if round_num > 0:
                cache_hits += len(test_tweets) - actual_requests
            
            total_requests += len(test_tweets)
            
            self.logger.info(f"è½®æ¬¡ {round_num + 1}: å®é™…APIè¯·æ±‚ {actual_requests}, é¢„æœŸè¯·æ±‚ {expected_requests}")
        
        cache_hit_rate = (cache_hits / max(total_requests - len(test_tweets), 1)) * 100  # æ’é™¤ç¬¬ä¸€è½®
        
        results = {
            'test_rounds': test_rounds,
            'total_potential_requests': total_requests,
            'cache_hits': cache_hits,
            'cache_hit_rate_percent': cache_hit_rate,
            'api_calls_saved': cache_hits
        }
        
        self.logger.info("=" * 50)
        self.logger.info("ç¼“å­˜æ•ˆæœ:")
        self.logger.info(f"æ€»æ½œåœ¨è¯·æ±‚æ•°: {total_requests}")
        self.logger.info(f"ç¼“å­˜å‘½ä¸­æ•°: {cache_hits}")
        self.logger.info(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1f}%")
        self.logger.info(f"èŠ‚çœAPIè°ƒç”¨: {cache_hits} æ¬¡")
        
        return results
    
    def run_complete_test(self) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æ‰¹å¤„ç†ä¼˜åŒ–æµ‹è¯•
        
        Returns:
            å®Œæ•´æµ‹è¯•ç»“æœ
        """
        self.logger.info("å¼€å§‹è¿è¡Œå®Œæ•´çš„æ‰¹å¤„ç†ä¼˜åŒ–æµ‹è¯•")
        self.logger.info("=" * 60)
        
        results = {}
        
        try:
            # æµ‹è¯•1: æ‰¹é‡è¯é¢˜æå–
            results['batch_topic_extraction'] = self.test_batch_topic_extraction()
            
            # æµ‹è¯•2: å†…å®¹é¢„ç­›é€‰
            results['content_filtering'] = self.test_content_filtering()
            
            # æµ‹è¯•3: å“åº”ç¼“å­˜
            results['cache_effectiveness'] = self.test_cache_effectiveness()
            
            # è®¡ç®—æ€»ä½“ä¼˜åŒ–æ•ˆæœ
            total_api_calls_saved = (
                results['batch_topic_extraction']['optimization_effect']['api_calls_saved'] +
                results['content_filtering']['potential_api_calls_saved'] +
                results['cache_effectiveness']['api_calls_saved']
            )
            
            results['summary'] = {
                'total_api_calls_saved': total_api_calls_saved,
                'optimization_strategies_tested': 3,
                'test_completion_time': datetime.now().isoformat()
            }
            
            self.logger.info("=" * 60)
            self.logger.info("æ‰¹å¤„ç†ä¼˜åŒ–æµ‹è¯•å®Œæˆ")
            self.logger.info(f"æ€»è®¡èŠ‚çœAPIè°ƒç”¨: {total_api_calls_saved} æ¬¡")
            
        except Exception as e:
            self.logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            results['error'] = str(e)
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("æ‰¹å¤„ç†ä¼˜åŒ–æµ‹è¯•è„šæœ¬")
    print("=" * 60)
    
    tester = BatchOptimizationTester()
    
    try:
        # è¿è¡Œå®Œæ•´æµ‹è¯•
        results = tester.run_complete_test()
        
        # è¾“å‡ºç»“æœ
        print("\næµ‹è¯•ç»“æœ:")
        print("=" * 60)
        
        if 'error' not in results:
            # æ‰¹é‡å¤„ç†æµ‹è¯•ç»“æœ
            batch_results = results.get('batch_topic_extraction', {})
            if batch_results:
                opt_effect = batch_results.get('optimization_effect', {})
                print(f"æ‰¹é‡å¤„ç†ä¼˜åŒ–:")
                print(f"  - APIè°ƒç”¨èŠ‚çœ: {opt_effect.get('api_calls_saved', 0)} æ¬¡ ({opt_effect.get('api_calls_saved_percent', 0):.1f}%)")
                print(f"  - æ—¶é—´èŠ‚çœ: {opt_effect.get('time_saved_seconds', 0):.2f} ç§’ ({opt_effect.get('time_saved_percent', 0):.1f}%)")
            
            # å†…å®¹ç­›é€‰æµ‹è¯•ç»“æœ
            filter_results = results.get('content_filtering', {})
            if filter_results:
                print(f"å†…å®¹é¢„ç­›é€‰:")
                print(f"  - è¿‡æ»¤ç‡: {filter_results.get('filter_rate_percent', 0):.1f}%")
                print(f"  - æ½œåœ¨èŠ‚çœAPIè°ƒç”¨: {filter_results.get('potential_api_calls_saved', 0)} æ¬¡")
            
            # ç¼“å­˜æµ‹è¯•ç»“æœ
            cache_results = results.get('cache_effectiveness', {})
            if cache_results:
                print(f"å“åº”ç¼“å­˜:")
                print(f"  - ç¼“å­˜å‘½ä¸­ç‡: {cache_results.get('cache_hit_rate_percent', 0):.1f}%")
                print(f"  - èŠ‚çœAPIè°ƒç”¨: {cache_results.get('api_calls_saved', 0)} æ¬¡")
            
            # æ€»ç»“
            summary = results.get('summary', {})
            print(f"\næ€»ä½“ä¼˜åŒ–æ•ˆæœ:")
            print(f"  - æ€»è®¡èŠ‚çœAPIè°ƒç”¨: {summary.get('total_api_calls_saved', 0)} æ¬¡")
        else:
            print(f"æµ‹è¯•å¤±è´¥: {results['error']}")
    
    except Exception as e:
        print(f"è¿è¡Œæµ‹è¯•æ—¶å‡ºé”™: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
