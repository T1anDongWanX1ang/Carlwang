# åŠ å¯†Twitteræ•°æ®æµæ°´çº¿ Architecture Document

## Introduction

æ­¤æ–‡æ¡£æ¦‚è¿°äº†**åŠ å¯†Twitteræ•°æ®æµæ°´çº¿**çš„æ•´ä½“é¡¹ç›®æ¶æ„ï¼ŒåŒ…æ‹¬åç«¯ç³»ç»Ÿã€å…±äº«æœåŠ¡å’Œè¡ç”ŸæŒ‡æ ‡è®¡ç®—å¼•æ“çš„è¯¦ç»†è®¾è®¡ã€‚å…¶ä¸»è¦ç›®æ ‡æ˜¯ä¸ºAIé©±åŠ¨çš„å¼€å‘æä¾›æŒ‡å¯¼æ€§çš„æ¶æ„è“å›¾ï¼Œç¡®ä¿ä¸€è‡´æ€§å’Œå¯¹æ‰€é€‰æ¨¡å¼å’ŒæŠ€æœ¯çš„éµå¾ªã€‚

### Starter Template or Existing Project

N/A - è¿™æ˜¯ä¸€ä¸ªä»é›¶å¼€å§‹çš„ç»¿åœ°é¡¹ç›®ï¼Œå°†æ„å»ºä¸“ä¸šçš„cryptoç¤¾äº¤æ•°æ®åŸºç¡€è®¾æ–½ã€‚

### Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-28 | 1.0 | åˆå§‹æ¶æ„æ–‡æ¡£åˆ›å»º | Architect |

## High Level Architecture

### Technical Summary

æœ¬ç³»ç»Ÿé‡‡ç”¨**æ··åˆå¾®æœåŠ¡æ¶æ„**ï¼Œç»“åˆ7ä¸ªå®ä½“é¢†åŸŸæœåŠ¡å’Œå…±äº«æ ¸å¿ƒç»„ä»¶ã€‚åŸºäº**äº‹ä»¶é©±åŠ¨æ¨¡å¼**å’Œ**å®æ—¶æµå¤„ç†**ï¼Œä½¿ç”¨Apache Kafkaä½œä¸ºæ¶ˆæ¯æ€»çº¿ã€‚æ ¸å¿ƒæŠ€æœ¯æ ˆä¸ºPython FastAPI + Goé«˜æ€§èƒ½æœåŠ¡ï¼Œé…åˆGPUé›†ç¾¤è¿›è¡ŒLLMæ¨ç†ã€‚æ¶æ„æ”¯æŒPRDä¸­å®šä¹‰çš„10,000+ QPSå’Œ<200mså“åº”æ—¶é—´è¦æ±‚ï¼ŒåŒæ—¶å®ç°ä¸‰å¤§æ ¸å¿ƒæŒ‡æ ‡ï¼ˆsentiment_indexã€popularityã€summaryï¼‰çš„å®æ—¶è®¡ç®—å’Œå†å²æ•°æ®ç§¯ç´¯ã€‚

### High Level Overview

**æ¶æ„é£æ ¼**: äº‹ä»¶é©±åŠ¨å¾®æœåŠ¡æ¶æ„ + Monorepo
- **Repositoryç»“æ„**: Monorepo - ä¾¿äº7ä¸ªå®ä½“æœåŠ¡çš„ä¾èµ–ç®¡ç†å’Œä»£ç å¤ç”¨
- **æœåŠ¡æ¶æ„**: é¢†åŸŸå¾®æœåŠ¡ + å…±äº«æœåŠ¡å±‚
  - 7ä¸ªå®ä½“å¾®æœåŠ¡ï¼šTweetã€Topicã€Userã€KOLã€Projectã€Narrativeã€Marco
  - å…±äº«æœåŠ¡ï¼šLLMæ¨ç†å¼•æ“ã€æ•°æ®é‡‡é›†å¼•æ“ã€APIç½‘å…³ã€å­˜å‚¨æŠ½è±¡å±‚
- **æ•°æ®æµ**: Twitteræ•°æ®é‡‡é›† â†’ å®æ—¶ETL â†’ 7å±‚å®ä½“å¤„ç† â†’ è¡ç”ŸæŒ‡æ ‡è®¡ç®— â†’ APIè¾“å‡º
- **å…³é”®å†³ç­–**: é€‰æ‹©äº‹ä»¶é©±åŠ¨æ¶æ„ä»¥æ”¯æŒå®æ—¶æ•°æ®å¤„ç†å’Œæ¾è€¦åˆè®¾è®¡

### High Level Project Diagram

```mermaid
graph TB
    subgraph "External Data Sources"
        A[Twitter API v2]
        B[Price Data APIs]
    end
    
    subgraph "Data Ingestion Layer"
        C[Data Collector Service]
        D[Raw Data Storage S3]
    end
    
    subgraph "Message Bus"
        E[Apache Kafka]
    end
    
    subgraph "Core Processing Services"
        F[Tweet Service]
        G[User Service]  
        H[KOL Service]
        I[Topic Service]
        J[Project Service]
        K[Narrative Service]
        L[Marco Service]
    end
    
    subgraph "Shared Services"
        M[LLM Inference Engine]
        N[Metrics Calculation Engine]
        O[API Gateway]
    end
    
    subgraph "Storage Layer"
        P[PostgreSQL]
        Q[InfluxDB]
        R[Redis Cache]
    end
    
    subgraph "Client Access"
        S[REST APIs]
        T[WebSocket APIs]
        U[Client SDKs]
    end
    
    A --> C
    B --> C
    C --> D
    C --> E
    E --> F
    E --> G
    E --> H
    E --> I
    E --> J
    E --> K
    E --> L
    F --> M
    G --> M
    H --> M
    I --> M
    J --> M
    K --> M
    L --> M
    M --> N
    N --> Q
    F --> P
    G --> P
    H --> P
    I --> P
    J --> P
    K --> P
    L --> P
    O --> R
    O --> S
    O --> T
    O --> U
```

### Architectural and Design Patterns

- **äº‹ä»¶é©±åŠ¨æ¶æ„**: ä½¿ç”¨Apache Kafkaå®ç°æœåŠ¡é—´è§£è€¦å’Œå¼‚æ­¥å¤„ç† - *ç†ç”±*: æ”¯æŒé«˜ååé‡æ•°æ®å¤„ç†å’Œç³»ç»Ÿå¼¹æ€§æ‰©å±•
- **CQRSæ¨¡å¼**: è¯»å†™åˆ†ç¦»ï¼Œå†™å…¥PostgreSQLï¼Œè¯»å–é€šè¿‡Redisç¼“å­˜ä¼˜åŒ– - *ç†ç”±*: æ»¡è¶³é«˜å¹¶å‘APIæŸ¥è¯¢éœ€æ±‚
- **Repositoryæ¨¡å¼**: æŠ½è±¡æ•°æ®è®¿é—®é€»è¾‘ï¼Œæ”¯æŒå¤šå­˜å‚¨åç«¯ - *ç†ç”±*: ä¾¿äºæµ‹è¯•å’Œæœªæ¥æ•°æ®åº“è¿ç§»
- **ç­–ç•¥æ¨¡å¼**: ä¸åŒå®ä½“çš„æŒ‡æ ‡è®¡ç®—ç®—æ³•å¯æ’æ‹” - *ç†ç”±*: æ”¯æŒæŒ‡æ ‡ç®—æ³•çš„ç‹¬ç«‹æ¼”è¿›å’ŒA/Bæµ‹è¯•
- **å‘å¸ƒ-è®¢é˜…æ¨¡å¼**: å®ä½“é—´æ•°æ®å˜åŒ–é€šè¿‡äº‹ä»¶é€šçŸ¥ - *ç†ç”±*: å®ç°æ¾è€¦åˆçš„æ•°æ®ä¸€è‡´æ€§ç®¡ç†
- **æ‰¹å¤„ç† + æµå¤„ç†æ··åˆ**: Apache Flinkå¤„ç†å®æ—¶æµï¼ŒSparkå¤„ç†å†å²æ‰¹é‡è®¡ç®— - *ç†ç”±*: å¹³è¡¡å®æ—¶æ€§å’Œè®¡ç®—æ•ˆç‡

## Tech Stack

### Cloud Infrastructure
- **Provider**: AWS (ä¸»å¹³å°) + GCP (å¤šäº‘å¤‡ä»½)
- **Key Services**: EKSã€RDSã€ElastiCacheã€S3ã€Lambdaã€SQS/SNS
- **Deployment Regions**: us-east-1 (ä¸»), eu-west-1 (å¤‡)

### Technology Stack Table

| Category | Technology | Version | Purpose | Rationale |
|----------|------------|---------|---------|-----------|
| **Runtime** | Python | 3.11.7 | æ•°æ®å¤„ç†å’ŒMLæœåŠ¡ | ä¸°å¯Œçš„æ•°æ®ç§‘å­¦ç”Ÿæ€ï¼ŒLLMé›†æˆæ”¯æŒ |
| **Runtime** | Go | 1.21.5 | é«˜æ€§èƒ½APIæœåŠ¡ | å¹¶å‘æ€§èƒ½ä¼˜å¼‚ï¼Œé€‚åˆé«˜QPSè¦æ±‚ |
| **Web Framework** | FastAPI | 0.104.1 | Python APIæœåŠ¡æ¡†æ¶ | å¼‚æ­¥æ”¯æŒï¼Œè‡ªåŠ¨APIæ–‡æ¡£ç”Ÿæˆ |
| **Web Framework** | Gin | 1.9.1 | Go APIæœåŠ¡æ¡†æ¶ | è½»é‡çº§ï¼Œé«˜æ€§èƒ½è·¯ç”± |
| **Message Queue** | Apache Kafka | 3.6.0 | äº‹ä»¶æµå¤„ç† | é«˜ååé‡ï¼ŒæŒä¹…åŒ–æ¶ˆæ¯å­˜å‚¨ |
| **Stream Processing** | Apache Flink | 1.18.0 | å®æ—¶æ•°æ®æµå¤„ç† | ä½å»¶è¿Ÿæµå¤„ç†ï¼ŒçŠ¶æ€ç®¡ç† |
| **Batch Processing** | Apache Spark | 3.5.0 | å†å²æ•°æ®æ‰¹å¤„ç† | å¤§è§„æ¨¡æ•°æ®å¤„ç†ï¼ŒMLæ”¯æŒ |
| **Database** | PostgreSQL | 16.1 | å…³ç³»æ•°æ®å­˜å‚¨ | ACIDäº‹åŠ¡ï¼Œå¤æ‚æŸ¥è¯¢æ”¯æŒ |
| **Time Series DB** | InfluxDB | 2.7.4 | æŒ‡æ ‡å†å²æ•°æ® | æ—¶åºæ•°æ®ä¼˜åŒ–ï¼Œé«˜å‹ç¼©æ¯” |
| **Cache** | Redis | 7.2.3 | çƒ­æ•°æ®ç¼“å­˜ | é«˜æ€§èƒ½é”®å€¼å­˜å‚¨ï¼Œæ”¯æŒæ•°æ®ç»“æ„ |
| **Object Storage** | AWS S3 | - | åŸå§‹æ•°æ®å­˜å‚¨ | æ— é™æ‰©å±•ï¼Œæˆæœ¬æ•ˆç›Š |
| **LLM Framework** | vLLM | 0.2.6 | LLMæ¨ç†åŠ é€Ÿ | GPUä¼˜åŒ–ï¼Œæ‰¹å¤„ç†æ”¯æŒ |
| **ML Model** | Llama-2-13B | 13B | æƒ…æ„Ÿåˆ†æå’ŒNER | å¼€æºï¼Œå¯fine-tune |
| **Container** | Docker | 24.0.7 | å®¹å™¨åŒ– | æ ‡å‡†åŒ–éƒ¨ç½²ç¯å¢ƒ |
| **Orchestration** | Kubernetes | 1.28.4 | å®¹å™¨ç¼–æ’ | è‡ªåŠ¨æ‰©ç¼©å®¹ï¼ŒæœåŠ¡å‘ç° |
| **API Gateway** | Kong | 3.4.2 | APIç®¡ç† | è®¤è¯ï¼Œé™æµï¼Œè·¯ç”± |
| **Monitoring** | Prometheus | 2.48.0 | æŒ‡æ ‡ç›‘æ§ | æ—¶åºæŒ‡æ ‡æ”¶é›† |
| **Visualization** | Grafana | 10.2.2 | ç›‘æ§é¢æ¿ | çµæ´»çš„ä»ªè¡¨æ¿ |
| **Logging** | ELK Stack | 8.11.0 | æ—¥å¿—ç®¡ç† | é›†ä¸­åŒ–æ—¥å¿—æœç´¢åˆ†æ |
| **CI/CD** | GitHub Actions | - | æŒç»­é›†æˆ | ä¸ä»£ç ä»“åº“é›†æˆ |
| **IaC** | Terraform | 1.6.6 | åŸºç¡€è®¾æ–½ä»£ç  | å¯é‡å¤åŸºç¡€è®¾æ–½éƒ¨ç½² |

## Data Models

### Tweet
**Purpose**: å­˜å‚¨Twitteræ¨æ–‡çš„å®Œæ•´ä¿¡æ¯å’ŒåŸºç¡€æŒ‡æ ‡

**Key Attributes**:
- tweet_id: String - Twitterå”¯ä¸€æ ‡è¯†ç¬¦
- content: Text - æ¨æ–‡å†…å®¹
- created_at: DateTime - å‘å¸ƒæ—¶é—´
- user_id: String - å‘å¸ƒç”¨æˆ·ID (å¤–é”®)
- engagement_metrics: JSON - äº’åŠ¨æ•°æ® {likes, retweets, replies, quotes}
- crypto_sentiment: String - cryptoæƒ…æ„Ÿåˆ†æç»“æœ
- is_important: Boolean - é‡è¦æ€§åˆ¤æ–­
- entity_mentions: JSON - æåŠçš„å®ä½“IDåˆ—è¡¨

**Relationships**:
- belongs_to User (å¤šå¯¹ä¸€)
- relates_to Topic (å¤šå¯¹å¤š)
- mentions Project (å¤šå¯¹å¤š)

### User  
**Purpose**: å­˜å‚¨Twitterç”¨æˆ·åŸºæœ¬ä¿¡æ¯å’Œå½±å“åŠ›æŒ‡æ ‡

**Key Attributes**:
- user_id: String - Twitterç”¨æˆ·ID
- screen_name: String - ç”¨æˆ·å (@username)
- display_name: String - æ˜¾ç¤ºåç§°
- bio: Text - ç”¨æˆ·ç®€ä»‹
- followers_count: Integer - ç²‰ä¸æ•°
- following_count: Integer - å…³æ³¨æ•°
- created_at: DateTime - è´¦å·åˆ›å»ºæ—¶é—´
- is_verified: Boolean - æ˜¯å¦è®¤è¯

**Relationships**:
- has_many Tweets (ä¸€å¯¹å¤š)
- can_be KOL (ä¸€å¯¹ä¸€)

### KOL
**Purpose**: å…³é”®æ„è§é¢†è¢–çš„ä¸“ä¸šåˆ†æå’Œå½±å“åŠ›é‡åŒ–

**Key Attributes**:
- kol_id: String - KOLå”¯ä¸€æ ‡è¯†
- user_id: String - å…³è”User ID (å¤–é”®)
- type: String - KOLç±»å‹ (founder/influencer/investor)
- influence_score: Float - ç»¼åˆå½±å“åŠ›è¯„åˆ† (0-100)
- call_accuracy_1h: Float - 1å°æ—¶å–Šå•å‡†ç¡®ç‡
- call_accuracy_24h: Float - 24å°æ—¶å–Šå•å‡†ç¡®ç‡  
- call_accuracy_3d: Float - 3å¤©å–Šå•å‡†ç¡®ç‡
- call_accuracy_7d: Float - 7å¤©å–Šå•å‡†ç¡®ç‡
- sentiment: String - å½“å‰å¸‚åœºæƒ…ç»ªå€¾å‘
- trust_rating: Integer - å¯ä¿¡åº¦è¯„çº§ (1-10)

**Relationships**:
- belongs_to User (ä¸€å¯¹ä¸€)
- interested_in Projects (å¤šå¯¹å¤š)
- discussed_in Topics (å¤šå¯¹å¤š)

### Topic
**Purpose**: è¯é¢˜èšç±»å’Œçƒ­åº¦è¿½è¸ª

**Key Attributes**:
- topic_id: String - è¯é¢˜å”¯ä¸€æ ‡è¯†
- name: String - è¯é¢˜åç§°
- description: Text - è¯é¢˜æè¿°
- created_at: DateTime - åˆ›å»ºæ—¶é—´
- popularity: Integer - çƒ­åº¦æŒ‡æ ‡
- propagation_speed_5m: Float - 5åˆ†é’Ÿä¼ æ’­é€Ÿåº¦
- propagation_speed_1h: Float - 1å°æ—¶ä¼ æ’­é€Ÿåº¦
- propagation_speed_4h: Float - 4å°æ—¶ä¼ æ’­é€Ÿåº¦

**Relationships**:  
- relates_to Tweets (å¤šå¯¹å¤š)
- discussed_by KOLs (å¤šå¯¹å¤š)
- belongs_to Projects (å¤šå¯¹å¤š)

### Project
**Purpose**: åŠ å¯†é¡¹ç›®ä¿¡æ¯å’Œç¤¾åŒºæƒ…ç»ª

**Key Attributes**:
- project_id: String - é¡¹ç›®å”¯ä¸€æ ‡è¯†
- name: String - é¡¹ç›®åç§°
- symbol: String - ä»£å¸ç¬¦å·
- token_address: String - ä»£å¸åˆçº¦åœ°å€
- category: String - é¡¹ç›®åˆ†ç±» (DeFi/Layer1/Layer2ç­‰)
- narrative: String - æ‰€å±å™äº‹æ ‡ç­¾
- sentiment_index: Float - é¡¹ç›®æƒ…æ„ŸæŒ‡æ•° (0-100)
- popularity: Integer - é¡¹ç›®çƒ­åº¦
- created_at: DateTime - çº³å…¥ç³»ç»Ÿæ—¶é—´

**Relationships**:
- belongs_to Narrative (å¤šå¯¹ä¸€)
- mentioned_in Tweets (å¤šå¯¹å¤š)
- discussed_in Topics (å¤šå¯¹å¤š)

### Narrative
**Purpose**: å¸‚åœºå™äº‹å’Œèµ›é“åˆ†ç±»

**Key Attributes**:
- narrative_id: String - å™äº‹å”¯ä¸€æ ‡è¯†
- name: String - å™äº‹åç§° (å¦‚"AI"ã€"DeFi"ã€"Layer2")
- created_at: DateTime - åˆ›å»ºæ—¶é—´
- sentiment_index: Float - å™äº‹æ•´ä½“æƒ…æ„Ÿ (0-100)
- popularity: Integer - å™äº‹çƒ­åº¦
- summary: Text - AIç”Ÿæˆçš„å™äº‹è§‚ç‚¹æ€»ç»“

**Relationships**:
- has_many Projects (ä¸€å¯¹å¤š)
- belongs_to Marco (å¤šå¯¹ä¸€)

### Marco
**Purpose**: å®è§‚å¸‚åœºæƒ…ç»ªå’Œé‡å¤§äº‹ä»¶

**Key Attributes**:
- id: String - è®°å½•å”¯ä¸€æ ‡è¯†
- timestamp: DateTime - æ—¶é—´æˆ³ (æ¯å°æ—¶è®°å½•)
- sentiment_index: Float - æ•´ä½“å¸‚åœºæƒ…æ„ŸæŒ‡æ•° (0-100)
- summary: Text - å¸‚åœºäº‹ä»¶å’Œæƒ…ç»ªæ€»ç»“

**Relationships**:
- aggregates_from Narratives (ä¸€å¯¹å¤š)

## Components

### Data Collector Service
**Responsibility**: è´Ÿè´£ä»å¤–éƒ¨æ•°æ®æºé‡‡é›†åŸå§‹æ•°æ®ï¼Œè¿›è¡Œåˆæ­¥æ¸…æ´—å’Œæ ¼å¼åŒ–

**Key Interfaces**:
- Twitter API v2 é›†æˆæ¥å£
- æ•°æ®è´¨é‡æ£€æŸ¥å’Œè¿‡æ»¤æ¥å£
- æ•°æ®å‘å¸ƒåˆ°Kafkaæ¥å£

**Dependencies**: Twitter APIã€Kafka Producerã€S3å­˜å‚¨

**Technology Stack**: Python FastAPIã€Twitter API SDKã€boto3

### LLM Inference Engine  
**Responsibility**: æä¾›ç»Ÿä¸€çš„LLMæ¨ç†æœåŠ¡ï¼Œæ”¯æŒæƒ…æ„Ÿåˆ†æã€å®ä½“è¯†åˆ«ã€å†…å®¹æ€»ç»“ç­‰åŠŸèƒ½

**Key Interfaces**:
- `/analyze/sentiment` - æƒ…æ„Ÿåˆ†ææ¥å£
- `/extract/entities` - å®ä½“è¯†åˆ«æ¥å£  
- `/generate/summary` - å†…å®¹æ€»ç»“æ¥å£
- `/classify/importance` - é‡è¦æ€§åˆ†ç±»æ¥å£

**Dependencies**: GPUé›†ç¾¤ã€æ¨¡å‹å­˜å‚¨ã€Redisç¼“å­˜

**Technology Stack**: Pythonã€vLLMã€CUDAã€Llama-2-13B

### Metrics Calculation Engine
**Responsibility**: è®¡ç®—ä¸‰å¤§æ ¸å¿ƒæŒ‡æ ‡å’Œå„ç±»è¡ç”ŸæŒ‡æ ‡ï¼Œæ”¯æŒå®æ—¶å’Œæ‰¹é‡è®¡ç®—æ¨¡å¼

**Key Interfaces**:
- `/calculate/sentiment_index` - æƒ…æ„ŸæŒ‡æ•°è®¡ç®—
- `/calculate/popularity` - çƒ­åº¦æŒ‡æ ‡è®¡ç®—
- `/calculate/propagation_speed` - ä¼ æ’­é€Ÿåº¦è®¡ç®—
- `/calculate/influence_score` - å½±å“åŠ›è¯„åˆ†è®¡ç®—

**Dependencies**: InfluxDBã€PostgreSQLã€Flink Runtime

**Technology Stack**: Pythonã€Apache Flinkã€InfluxDB Client

### Tweet Service
**Responsibility**: å¤„ç†Tweetå®ä½“çš„CRUDæ“ä½œå’Œä¸šåŠ¡é€»è¾‘

**Key Interfaces**:
- RESTful CRUD APIs
- äº‹ä»¶å¤„ç†æ¥å£ (Kafka Consumer)
- æ•°æ®å…³ç³»å»ºç«‹æ¥å£

**Dependencies**: PostgreSQLã€Kafkaã€LLM Inference Engine

**Technology Stack**: Python FastAPIã€SQLAlchemyã€Kafka Client

### KOL Service  
**Responsibility**: KOLè¯†åˆ«ã€åˆ†ç±»ã€å½±å“åŠ›è¯„åˆ†å’Œå–Šå•æ•ˆæœè¿½è¸ª

**Key Interfaces**:
- `/kol/identify` - KOLè¯†åˆ«æ¥å£
- `/kol/classify` - KOLåˆ†ç±»æ¥å£
- `/kol/influence/calculate` - å½±å“åŠ›è®¡ç®—æ¥å£
- `/kol/call/track` - å–Šå•è¿½è¸ªæ¥å£

**Dependencies**: User Serviceã€Price Data APIsã€Metrics Engine

**Technology Stack**: Python FastAPIã€pandasã€scikit-learn

### API Gateway Service
**Responsibility**: ç»Ÿä¸€APIå…¥å£ï¼Œå¤„ç†è®¤è¯ã€æˆæƒã€é™æµã€è·¯ç”±

**Key Interfaces**:
- å®¢æˆ·ç«¯APIä»£ç†
- WebSocketè¿æ¥ç®¡ç†  
- è®¤è¯å’Œæˆæƒä¸­é—´ä»¶
- æŒ‡æ ‡æ”¶é›†å’Œç›‘æ§

**Dependencies**: æ‰€æœ‰å¾®æœåŠ¡ã€Redisã€Kong

**Technology Stack**: Kong Gatewayã€Redisã€Prometheus

### Component Diagrams

```mermaid
graph TD
    subgraph "Data Flow"
        A[Twitter Data] --> B[Data Collector]
        B --> C[Kafka Topics]
        C --> D[Entity Services]
        D --> E[LLM Engine]
        E --> F[Metrics Engine]
        F --> G[Storage Layer]
    end
    
    subgraph "Service Communication"  
        H[API Gateway] --> I[Entity Services]
        I --> J[Shared Services]
        J --> K[Storage Backends]
    end
```

## External APIs

### Twitter API v2
- **Purpose**: è·å–å®æ—¶æ¨æ–‡æ•°æ®å’Œç”¨æˆ·ä¿¡æ¯
- **Documentation**: https://developer.twitter.com/en/docs/twitter-api
- **Base URL(s)**: https://api.twitter.com/2/
- **Authentication**: Bearer Token (OAuth 2.0)
- **Rate Limits**: 300 requests/15åˆ†é’Ÿ (Standard), 1000 requests/15åˆ†é’Ÿ (Enterprise)

**Key Endpoints Used**:
- `GET /2/tweets/search/stream` - å®æ—¶æ¨æ–‡æµé‡‡é›†
- `GET /2/users/by` - æ‰¹é‡ç”¨æˆ·ä¿¡æ¯è·å–
- `GET /2/tweets` - æ¨æ–‡è¯¦æƒ…æŸ¥è¯¢

**Integration Notes**: éœ€è¦Enterpriseçº§åˆ«è®¢é˜…ä»¥æ”¯æŒå¤§è§„æ¨¡æ•°æ®é‡‡é›†éœ€æ±‚

### CoinGecko API
- **Purpose**: è·å–åŠ å¯†è´§å¸ä»·æ ¼æ•°æ®ï¼Œç”¨äºKOLå–Šå•æ•ˆæœè®¡ç®—
- **Documentation**: https://www.coingecko.com/en/api/documentation
- **Base URL(s)**: https://api.coingecko.com/api/v3/
- **Authentication**: API Key (Pro Plan)
- **Rate Limits**: 10,000 calls/æœˆ (Free), 500 calls/åˆ†é’Ÿ (Pro)

**Key Endpoints Used**:
- `GET /simple/price` - å½“å‰ä»·æ ¼æŸ¥è¯¢
- `GET /coins/{id}/history` - å†å²ä»·æ ¼æ•°æ®
- `GET /coins/list` - å¸ç§åˆ—è¡¨

**Integration Notes**: ç”¨äºè®¡ç®—KOLå–Šå•åçš„ä»·æ ¼å˜åŒ–æ•ˆæœ

## Core Workflows

### Real-time Tweet Processing Workflow

```mermaid
sequenceDiagram
    participant T as Twitter API
    participant DC as Data Collector
    participant K as Kafka
    participant TS as Tweet Service
    participant LLM as LLM Engine
    participant ME as Metrics Engine
    participant DB as Database
    
    T->>DC: Stream tweets
    DC->>DC: Filter & validate
    DC->>K: Publish tweet event
    K->>TS: Consume tweet event
    TS->>LLM: Analyze sentiment
    LLM-->>TS: Return analysis
    TS->>DB: Store tweet + analysis
    TS->>K: Publish processed event
    K->>ME: Consume for metrics
    ME->>DB: Update derived metrics
```

### KOL Call Tracking Workflow

```mermaid
sequenceDiagram
    participant KOL as KOL Service
    participant LLM as LLM Engine
    participant PA as Price API
    participant ME as Metrics Engine
    participant DB as Database
    
    KOL->>LLM: Identify call in tweet
    LLM-->>KOL: Extract project & prediction
    KOL->>PA: Get current price
    PA-->>KOL: Return price data
    KOL->>DB: Store call record
    
    Note over KOL,DB: Wait for tracking period
    
    KOL->>PA: Get price after 1h/24h/3d/7d
    PA-->>KOL: Return updated price
    KOL->>ME: Calculate accuracy
    ME-->>KOL: Return accuracy score
    KOL->>DB: Update KOL metrics
```

## REST API Spec

```yaml
openapi: 3.0.0
info:
  title: Crypto Twitter Data Pipeline API
  version: 1.0.0
  description: RESTful API for crypto social media data and analytics

servers:
  - url: https://api.cryptotwitterdata.com/v1
    description: Production API server

components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key
  
  schemas:
    Tweet:
      type: object
      properties:
        tweet_id:
          type: string
        content:
          type: string
        created_at:
          type: string
          format: date-time
        user_id:
          type: string
        sentiment_index:
          type: number
          minimum: 0
          maximum: 100
        is_important:
          type: boolean
        engagement_metrics:
          type: object
          properties:
            likes:
              type: integer
            retweets:
              type: integer
            replies:
              type: integer
            quotes:
              type: integer
    
    KOL:
      type: object
      properties:
        kol_id:
          type: string
        user_id:
          type: string
        type:
          type: string
          enum: [founder, influencer, investor]
        influence_score:
          type: number
          minimum: 0
          maximum: 100
        call_accuracy_24h:
          type: number
          minimum: 0
          maximum: 100
        sentiment:
          type: string
          enum: [bullish, bearish, neutral]

security:
  - ApiKeyAuth: []

paths:
  /tweets:
    get:
      summary: Get tweets with filtering options
      parameters:
        - name: user_id
          in: query
          schema:
            type: string
        - name: sentiment
          in: query
          schema:
            type: string
            enum: [positive, negative, neutral]
        - name: start_time
          in: query
          schema:
            type: string
            format: date-time
        - name: limit
          in: query
          schema:
            type: integer
            default: 100
            maximum: 1000
      responses:
        '200':
          description: List of tweets
          content:
            application/json:
              schema:
                type: object
                properties:
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/Tweet'
                  pagination:
                    type: object
                    properties:
                      page:
                        type: integer
                      total:
                        type: integer
                      has_more:
                        type: boolean
  
  /kols:
    get:
      summary: Get KOL rankings and information
      parameters:
        - name: type
          in: query
          schema:
            type: string
            enum: [founder, influencer, investor]
        - name: sort_by
          in: query
          schema:
            type: string
            enum: [influence_score, call_accuracy_24h]
            default: influence_score
        - name: limit
          in: query
          schema:
            type: integer
            default: 50
            maximum: 500
      responses:
        '200':
          description: List of KOLs
          content:
            application/json:
              schema:
                type: object
                properties:
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/KOL'
  
  /metrics/sentiment_index:
    get:
      summary: Get sentiment index for different entities
      parameters:
        - name: entity_type
          in: query
          required: true
          schema:
            type: string
            enum: [tweet, kol, project, narrative, marco]
        - name: entity_id
          in: query
          schema:
            type: string
        - name: timerange
          in: query
          schema:
            type: string
            enum: [1h, 24h, 7d, 30d]
            default: 24h
      responses:
        '200':
          description: Sentiment index data
          content:
            application/json:
              schema:
                type: object
                properties:
                  entity_type:
                    type: string
                  entity_id:
                    type: string
                  current_sentiment:
                    type: number
                  historical_data:
                    type: array
                    items:
                      type: object
                      properties:
                        timestamp:
                          type: string
                          format: date-time
                        value:
                          type: number
```

## Database Schema

### PostgreSQL Schema (å…³ç³»æ•°æ®)

```sql
-- Usersè¡¨
CREATE TABLE users (
    user_id VARCHAR(50) PRIMARY KEY,
    screen_name VARCHAR(50) NOT NULL,
    display_name VARCHAR(100),
    bio TEXT,
    followers_count INTEGER DEFAULT 0,
    following_count INTEGER DEFAULT 0,
    statuses_count INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_verified BOOLEAN DEFAULT FALSE
);

-- Tweetsè¡¨  
CREATE TABLE tweets (
    tweet_id VARCHAR(50) PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL REFERENCES users(user_id),
    content TEXT NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL,
    is_quote BOOLEAN DEFAULT FALSE,
    in_reply_to_id VARCHAR(50),
    quote_count INTEGER DEFAULT 0,
    reply_count INTEGER DEFAULT 0,
    retweet_count INTEGER DEFAULT 0,
    favorite_count INTEGER DEFAULT 0,
    bookmark_count INTEGER DEFAULT 0,
    view_count INTEGER DEFAULT 0,
    crypto_sentiment VARCHAR(20),
    is_important BOOLEAN DEFAULT FALSE,
    entity_mentions JSONB,
    processed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- KOLsè¡¨
CREATE TABLE kols (
    kol_id VARCHAR(50) PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL REFERENCES users(user_id),
    type VARCHAR(20) NOT NULL CHECK (type IN ('founder', 'influencer', 'investor')),
    influence_score DECIMAL(5,2) DEFAULT 0,
    call_accuracy_1h DECIMAL(5,2),
    call_accuracy_24h DECIMAL(5,2), 
    call_accuracy_3d DECIMAL(5,2),
    call_accuracy_7d DECIMAL(5,2),
    sentiment VARCHAR(20) DEFAULT 'neutral',
    trust_rating INTEGER CHECK (trust_rating >= 1 AND trust_rating <= 10),
    is_kol100 BOOLEAN DEFAULT FALSE,
    tags VARCHAR(200),
    summary TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Topicsè¡¨
CREATE TABLE topics (
    topic_id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(200) NOT NULL,
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    popularity INTEGER DEFAULT 0,
    propagation_speed_5m DECIMAL(8,4),
    propagation_speed_1h DECIMAL(8,4),
    propagation_speed_4h DECIMAL(8,4),
    kol_opinion TEXT,
    kol_opinion_direction VARCHAR(20),
    mob_opinion_direction VARCHAR(20),
    summary TEXT
);

-- Projectsè¡¨
CREATE TABLE projects (
    project_id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    symbol VARCHAR(20),
    token_address VARCHAR(100),
    twitter_id VARCHAR(50),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    category VARCHAR(50),
    narrative VARCHAR(100),
    sentiment_index DECIMAL(5,2) DEFAULT 0,
    popularity INTEGER DEFAULT 0,
    summary TEXT
);

-- Narrativesè¡¨  
CREATE TABLE narratives (
    narrative_id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    sentiment_index DECIMAL(5,2) DEFAULT 0,
    popularity INTEGER DEFAULT 0,
    summary TEXT
);

-- Marcoè¡¨ (å®è§‚å¸‚åœºæ•°æ®)
CREATE TABLE marco_snapshots (
    id VARCHAR(50) PRIMARY KEY,
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    sentiment_index DECIMAL(5,2) DEFAULT 0,
    summary TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- å…³ç³»è¡¨
CREATE TABLE tweet_topics (
    tweet_id VARCHAR(50) REFERENCES tweets(tweet_id),
    topic_id VARCHAR(50) REFERENCES topics(topic_id),
    PRIMARY KEY (tweet_id, topic_id)
);

CREATE TABLE tweet_projects (
    tweet_id VARCHAR(50) REFERENCES tweets(tweet_id), 
    project_id VARCHAR(50) REFERENCES projects(project_id),
    PRIMARY KEY (tweet_id, project_id)
);

CREATE TABLE kol_calls (
    call_id VARCHAR(50) PRIMARY KEY,
    kol_id VARCHAR(50) REFERENCES kols(kol_id),
    tweet_id VARCHAR(50) REFERENCES tweets(tweet_id),
    project_id VARCHAR(50) REFERENCES projects(project_id),
    prediction_type VARCHAR(20), -- 'bullish', 'bearish'
    call_price DECIMAL(20,8),
    call_time TIMESTAMP WITH TIME ZONE,
    price_1h DECIMAL(20,8),
    price_24h DECIMAL(20,8),
    price_3d DECIMAL(20,8), 
    price_7d DECIMAL(20,8),
    accuracy_1h DECIMAL(5,2),
    accuracy_24h DECIMAL(5,2),
    accuracy_3d DECIMAL(5,2),
    accuracy_7d DECIMAL(5,2),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_tweets_created_at ON tweets(created_at);
CREATE INDEX idx_tweets_user_id ON tweets(user_id);
CREATE INDEX idx_tweets_sentiment ON tweets(crypto_sentiment);
CREATE INDEX idx_kols_influence_score ON kols(influence_score DESC);
CREATE INDEX idx_kols_type ON kols(type);
CREATE INDEX idx_projects_narrative ON projects(narrative);
CREATE INDEX idx_marco_timestamp ON marco_snapshots(timestamp);
```

### InfluxDB Schema (æ—¶åºæŒ‡æ ‡æ•°æ®)

```
# Measurement: sentiment_index
# å­˜å‚¨å„å®ä½“çš„æƒ…æ„ŸæŒ‡æ•°æ—¶åºæ•°æ®
sentiment_index,entity_type=tweet,entity_id=123456789 value=75.5 1640995200000000000
sentiment_index,entity_type=kol,entity_id=kol_001 value=82.3 1640995200000000000
sentiment_index,entity_type=project,entity_id=project_btc value=68.7 1640995200000000000

# Measurement: popularity
# å­˜å‚¨å„å®ä½“çš„çƒ­åº¦æŒ‡æ ‡æ—¶åºæ•°æ®  
popularity,entity_type=topic,entity_id=topic_defi value=1250 1640995200000000000
popularity,entity_type=project,entity_id=project_eth value=2100 1640995200000000000

# Measurement: propagation_speed
# å­˜å‚¨è¯é¢˜ä¼ æ’­é€Ÿåº¦æ•°æ®
propagation_speed,topic_id=topic_001,timeframe=5m value=15.7 1640995200000000000
propagation_speed,topic_id=topic_001,timeframe=1h value=45.2 1640995200000000000

# Measurement: kol_metrics
# å­˜å‚¨KOLç›¸å…³æŒ‡æ ‡æ—¶åºæ•°æ®
kol_metrics,kol_id=kol_001,metric=influence_score value=85.4 1640995200000000000
kol_metrics,kol_id=kol_001,metric=call_accuracy_24h value=72.8 1640995200000000000

# Measurement: system_metrics
# å­˜å‚¨ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
system_metrics,service=api_gateway,metric=requests_per_second value=8540 1640995200000000000
system_metrics,service=llm_engine,metric=inference_latency value=1.8 1640995200000000000
```

## Source Tree

```plaintext
ct_data_pipeline/
â”œâ”€â”€ services/                           # å¾®æœåŠ¡ç›®å½•
â”‚   â”œâ”€â”€ data-collector/                 # æ•°æ®é‡‡é›†æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ collectors/            # Twitter APIé‡‡é›†å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ processors/            # æ•°æ®é¢„å¤„ç†
â”‚   â”‚   â”‚   â””â”€â”€ publishers/            # Kafkaå‘å¸ƒè€…
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ llm-inference/                  # LLMæ¨ç†æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ models/               # æ¨¡å‹åŠ è½½å’Œç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ inference/            # æ¨ç†å¼•æ“
â”‚   â”‚   â”‚   â””â”€â”€ cache/                # æ¨ç†ç»“æœç¼“å­˜
â”‚   â”‚   â”œâ”€â”€ models/                   # é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ metrics-engine/                # æŒ‡æ ‡è®¡ç®—å¼•æ“
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ calculators/          # å„ç±»æŒ‡æ ‡è®¡ç®—å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ aggregators/          # æ•°æ®èšåˆå™¨
â”‚   â”‚   â”‚   â””â”€â”€ schedulers/           # å®šæ—¶ä»»åŠ¡è°ƒåº¦
â”‚   â”‚   â””â”€â”€ flink-jobs/               # Flinkä½œä¸šå®šä¹‰
â”‚   â”œâ”€â”€ tweet-service/                 # Tweetå®ä½“æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ handlers/             # HTTPå¤„ç†å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ models/               # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ repositories/         # æ•°æ®è®¿é—®å±‚
â”‚   â”‚   â”‚   â””â”€â”€ events/               # äº‹ä»¶å¤„ç†
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ kol-service/                   # KOLæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ identification/       # KOLè¯†åˆ«ç®—æ³•
â”‚   â”‚   â”‚   â”œâ”€â”€ influence/           # å½±å“åŠ›è®¡ç®—
â”‚   â”‚   â”‚   â”œâ”€â”€ tracking/            # å–Šå•è¿½è¸ª
â”‚   â”‚   â”‚   â””â”€â”€ classification/      # KOLåˆ†ç±»
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ user-service/                  # ç”¨æˆ·æœåŠ¡
â”‚   â”œâ”€â”€ topic-service/                 # è¯é¢˜æœåŠ¡
â”‚   â”œâ”€â”€ project-service/               # é¡¹ç›®æœåŠ¡
â”‚   â”œâ”€â”€ narrative-service/             # å™äº‹æœåŠ¡
â”‚   â”œâ”€â”€ marco-service/                 # å®è§‚æœåŠ¡
â”‚   â””â”€â”€ api-gateway/                   # APIç½‘å…³
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ routes/               # è·¯ç”±å®šä¹‰
â”‚       â”‚   â”œâ”€â”€ middleware/           # ä¸­é—´ä»¶
â”‚       â”‚   â”œâ”€â”€ auth/                 # è®¤è¯æˆæƒ
â”‚       â”‚   â””â”€â”€ rate-limiting/        # é™æµæ§åˆ¶
â”‚       â”œâ”€â”€ go.mod
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ shared/                            # å…±äº«åº“å’Œå·¥å…·
â”‚   â”œâ”€â”€ models/                       # å…±äº«æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ events/                       # äº‹ä»¶å®šä¹‰
â”‚   â”œâ”€â”€ clients/                      # å¤–éƒ¨APIå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ utils/                        # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ config/                       # é…ç½®ç®¡ç†
â”œâ”€â”€ infrastructure/                    # åŸºç¡€è®¾æ–½ä»£ç 
â”‚   â”œâ”€â”€ terraform/                    # Terraform IaC
â”‚   â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â””â”€â”€ production/
â”‚   â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”‚   â”œâ”€â”€ databases/
â”‚   â”‚   â”‚   â””â”€â”€ networking/
â”‚   â”‚   â””â”€â”€ main.tf
â”‚   â”œâ”€â”€ kubernetes/                   # K8sèµ„æºå®šä¹‰
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â””â”€â”€ overlays/
â”‚   â””â”€â”€ docker-compose/               # æœ¬åœ°å¼€å‘ç¯å¢ƒ
â”‚       â”œâ”€â”€ docker-compose.yml
â”‚       â””â”€â”€ docker-compose.override.yml
â”œâ”€â”€ scripts/                          # æ„å»ºå’Œéƒ¨ç½²è„šæœ¬
â”‚   â”œâ”€â”€ build.sh
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â”œâ”€â”€ migrate.sh
â”‚   â””â”€â”€ seed-data.sh
â”œâ”€â”€ docs/                             # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ api/                          # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ architecture/                 # æ¶æ„æ–‡æ¡£
â”‚   â””â”€â”€ deployment/                   # éƒ¨ç½²æŒ‡å—
â”œâ”€â”€ tests/                            # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ e2e/                         # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ integration/                 # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ load/                        # è´Ÿè½½æµ‹è¯•
â”œâ”€â”€ .github/                          # GitHub Actions
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml
â”‚       â”œâ”€â”€ cd.yml
â”‚       â””â”€â”€ security-scan.yml
â”œâ”€â”€ go.work                           # Go workspaceé…ç½®
â”œâ”€â”€ docker-compose.yml                # å¼€å‘ç¯å¢ƒ
â”œâ”€â”€ Makefile                          # æ„å»ºå‘½ä»¤
â””â”€â”€ README.md
```

## Derived Metrics Calculation Details

### Sentiment Indexè®¡ç®—å¼•æ“

**ç®—æ³•è®¾è®¡**:

1. **Tweetçº§åˆ«Sentiment Index**:
```python
def calculate_tweet_sentiment(tweet_content: str) -> float:
    # LLMæ¨ç†è·å–æƒ…æ„Ÿåˆ†ç±»å’Œç½®ä¿¡åº¦
    sentiment_result = llm_inference_client.analyze_sentiment(
        text=tweet_content,
        domain="cryptocurrency",
        output_format="score_and_confidence"
    )
    
    # è½¬æ¢ä¸º0-100åˆ†æ•°
    if sentiment_result.label == "positive":
        base_score = 50 + (sentiment_result.confidence * 50)
    elif sentiment_result.label == "negative": 
        base_score = 50 - (sentiment_result.confidence * 50)
    else:  # neutral
        base_score = 50
    
    # é‡è¦æ€§æƒé‡è°ƒæ•´
    if tweet.is_important:
        importance_weight = 1.2
    else:
        importance_weight = 1.0
        
    return min(100, max(0, base_score * importance_weight))
```

2. **KOLçº§åˆ«Sentiment Index**:
```python  
def calculate_kol_sentiment(kol_id: str, timeframe: str = "24h") -> float:
    # è·å–KOLåœ¨æ—¶é—´çª—å£å†…çš„æ‰€æœ‰æ¨æ–‡
    tweets = get_kol_tweets(kol_id, timeframe)
    
    # åŠ æƒå¹³å‡è®¡ç®—ï¼Œrecent tweetsæƒé‡æ›´é«˜
    total_weight = 0
    weighted_sentiment = 0
    
    for tweet in tweets:
        # æ—¶é—´è¡°å‡æƒé‡ (è¶Šæ–°æƒé‡è¶Šå¤§)
        time_weight = calculate_time_decay_weight(tweet.created_at)
        # äº’åŠ¨é‡æƒé‡
        engagement_weight = calculate_engagement_weight(tweet.engagement_metrics)
        
        final_weight = time_weight * engagement_weight
        weighted_sentiment += tweet.sentiment_index * final_weight
        total_weight += final_weight
    
    return weighted_sentiment / total_weight if total_weight > 0 else 50
```

3. **Projectçº§åˆ«Sentiment Index**:
```python
def calculate_project_sentiment(project_id: str, timeframe: str = "24h") -> float:
    # è·å–é¡¹ç›®ç›¸å…³çš„æ‰€æœ‰æ¨æ–‡å’ŒKOLè§‚ç‚¹
    project_tweets = get_project_tweets(project_id, timeframe)
    kol_opinions = get_kol_opinions_on_project(project_id, timeframe)
    
    # KOLè§‚ç‚¹æƒé‡ (70%) + æ™®é€šæ¨æ–‡æƒé‡ (30%)
    kol_sentiment = 0
    kol_weight = 0
    
    for opinion in kol_opinions:
        influence_weight = opinion.kol.influence_score / 100
        kol_sentiment += opinion.sentiment_index * influence_weight
        kol_weight += influence_weight
    
    avg_kol_sentiment = kol_sentiment / kol_weight if kol_weight > 0 else 50
    
    # æ™®é€šæ¨æ–‡æƒ…æ„Ÿ
    general_sentiment = sum(t.sentiment_index for t in project_tweets) / len(project_tweets)
    
    return avg_kol_sentiment * 0.7 + general_sentiment * 0.3
```

### PopularityæŒ‡æ ‡è®¡ç®—å¼•æ“

**å¤šç»´åº¦Popularityè®¡ç®—**:

```python
def calculate_topic_popularity(topic_id: str) -> int:
    # è·å–è¯é¢˜ç›¸å…³æ•°æ®
    topic_tweets = get_topic_tweets(topic_id, "24h")
    topic_kols = get_topic_kols(topic_id, "24h")
    
    # 1. æ¨æ–‡æ•°é‡åŸºç¡€åˆ† (40%)
    tweet_count_score = min(1000, len(topic_tweets))
    
    # 2. äº’åŠ¨è´¨é‡åˆ† (30%)  
    total_engagement = sum(
        t.like_count + t.retweet_count * 2 + t.reply_count * 1.5 
        for t in topic_tweets
    )
    engagement_score = min(1000, total_engagement / 10)
    
    # 3. KOLå‚ä¸åº¦åˆ† (20%)
    kol_participation = 0
    for kol in topic_kols:
        kol_participation += kol.influence_score * len(kol.topic_tweets)
    kol_score = min(1000, kol_participation / 100)
    
    # 4. ä¼ æ’­é€Ÿåº¦åŠ æˆ (10%)
    propagation_bonus = calculate_propagation_bonus(topic_id)
    
    popularity = int(
        tweet_count_score * 0.4 + 
        engagement_score * 0.3 + 
        kol_score * 0.2 + 
        propagation_bonus * 0.1
    )
    
    return popularity

def calculate_propagation_bonus(topic_id: str) -> float:
    # è·å–ä¼ æ’­é€Ÿåº¦æ•°æ®
    speed_5m = get_propagation_speed(topic_id, "5m")
    speed_1h = get_propagation_speed(topic_id, "1h") 
    
    # ç—…æ¯’å¼ä¼ æ’­æ£€æµ‹
    if speed_5m > 50 and speed_1h > 100:
        return 500  # ç—…æ¯’å¼ä¼ æ’­åŠ æˆ
    elif speed_5m > 20:
        return 200  # å¿«é€Ÿä¼ æ’­åŠ æˆ
    else:
        return 0
```

### Summary AIæ€»ç»“ç”Ÿæˆå¼•æ“

**åˆ†å±‚æ€»ç»“ç­–ç•¥**:

```python
def generate_kol_summary(kol_id: str, timeframe: str = "24h") -> str:
    # è·å–KOLæœ€æ–°è§‚ç‚¹æ¨æ–‡
    recent_tweets = get_kol_important_tweets(kol_id, timeframe, limit=10)
    
    # æ„å»ºä¸“ç”¨prompt
    prompt = f"""
    ä½œä¸ºcryptoå¸‚åœºåˆ†æå¸ˆï¼Œè¯·æ€»ç»“ä»¥ä¸‹KOLåœ¨è¿‡å»{timeframe}çš„ä¸»è¦è§‚ç‚¹ï¼š
    
    KOLç±»å‹: {kol.type}
    å½±å“åŠ›è¯„åˆ†: {kol.influence_score}
    
    ç›¸å…³æ¨æ–‡:
    {format_tweets_for_analysis(recent_tweets)}
    
    è¯·æä¾›:
    1. æ ¸å¿ƒè§‚ç‚¹æ‘˜è¦ (50å­—ä»¥å†…)
    2. å¸‚åœºæ€åº¦å€¾å‘ (bullish/bearish/neutral)
    3. é‡ç‚¹å…³æ³¨çš„é¡¹ç›®æˆ–å™äº‹
    
    è¾“å‡ºæ ¼å¼: ç®€æ´çš„ä¸­æ–‡æ€»ç»“ï¼Œçªå‡ºå…³é”®ä¿¡æ¯ã€‚
    """
    
    summary = llm_inference_client.generate_text(
        prompt=prompt,
        max_tokens=200,
        temperature=0.3
    )
    
    return summary.strip()

def generate_project_summary(project_id: str, timeframe: str = "24h") -> str:
    # è·å–é¡¹ç›®ç›¸å…³è®¨è®º
    project_tweets = get_project_tweets(project_id, timeframe)
    kol_opinions = get_project_kol_opinions(project_id, timeframe)
    
    # ç»Ÿè®¡å…³é”®æ•°æ®
    sentiment_stats = calculate_sentiment_distribution(project_tweets)
    top_topics = get_project_top_topics(project_id, timeframe)
    
    prompt = f"""
    è¯·æ€»ç»“é¡¹ç›® {project.name} ({project.symbol}) åœ¨è¿‡å»{timeframe}çš„ç¤¾åŒºè®¨è®ºæƒ…å†µï¼š
    
    è®¨è®ºæ•°æ®:
    - ç›¸å…³æ¨æ–‡æ•°é‡: {len(project_tweets)}
    - æƒ…æ„Ÿåˆ†å¸ƒ: {sentiment_stats}
    - çƒ­é—¨è¯é¢˜: {top_topics}
    - KOLè§‚ç‚¹æ•°: {len(kol_opinions)}
    
    é‡è¦è®¨è®ºå†…å®¹:
    {format_discussions_for_analysis(project_tweets[:5])}
    
    è¯·æä¾›ç®€æ´çš„é¡¹ç›®ç¤¾åŒºæƒ…ç»ªå’Œè®¨è®ºç„¦ç‚¹æ€»ç»“ã€‚
    """
    
    summary = llm_inference_client.generate_text(
        prompt=prompt,
        max_tokens=300,
        temperature=0.2
    )
    
    return summary.strip()
```

### KOLå½±å“åŠ›è¯„åˆ†ç®—æ³•

**ç»¼åˆå½±å“åŠ›è®¡ç®—**:

```python
def calculate_influence_score(kol_id: str) -> float:
    kol = get_kol_by_id(kol_id)
    user = get_user_by_id(kol.user_id)
    
    # 1. åŸºç¡€å½±å“åŠ› (30%) - åŸºäºç²‰ä¸æ•°å’Œè´¦å·è´¨é‡
    follower_score = min(30, math.log10(user.followers_count + 1) * 3)
    
    # 2. å†…å®¹è´¨é‡ (25%) - åŸºäºåŸåˆ›æ€§å’Œé‡è¦æ€§
    recent_tweets = get_user_tweets(user.user_id, "30d")
    important_tweets = [t for t in recent_tweets if t.is_important]
    quality_score = (len(important_tweets) / len(recent_tweets)) * 25
    
    # 3. äº’åŠ¨è´¨é‡ (20%) - åŸºäºçœŸå®äº’åŠ¨vs botäº’åŠ¨
    engagement_quality = calculate_engagement_quality(recent_tweets)
    interaction_score = engagement_quality * 20
    
    # 4. é¢„æµ‹å‡†ç¡®æ€§ (15%) - åŸºäºå–Šå•å†å²è¡¨ç°
    accuracy_score = 0
    if kol.call_accuracy_24h:
        accuracy_score = kol.call_accuracy_24h * 0.15
    
    # 5. ç½‘ç»œå½±å“åŠ› (10%) - åŸºäºè¢«å…¶ä»–KOLå¼•ç”¨/è½¬å‘çš„é¢‘ç‡
    network_influence = calculate_network_influence(kol_id)
    network_score = network_influence * 10
    
    total_score = (follower_score + quality_score + interaction_score + 
                  accuracy_score + network_score)
    
    return min(100, max(0, total_score))

def calculate_engagement_quality(tweets: List[Tweet]) -> float:
    # è®¡ç®—äº’åŠ¨è´¨é‡ï¼Œæ£€æµ‹botäº’åŠ¨æ¨¡å¼
    total_quality = 0
    
    for tweet in tweets:
        # äº’åŠ¨æ¯”ä¾‹åˆ†æ - æ­£å¸¸ç”¨æˆ·äº’åŠ¨æ¨¡å¼
        total_engagement = (tweet.like_count + tweet.retweet_count + 
                          tweet.reply_count)
        
        if total_engagement == 0:
            quality = 0
        else:
            # æ­£å¸¸æ¯”ä¾‹: likes > retweets > replies
            like_ratio = tweet.like_count / total_engagement
            retweet_ratio = tweet.retweet_count / total_engagement
            
            # å¼‚å¸¸æ¨¡å¼æ£€æµ‹ (å¯èƒ½çš„botè¡Œä¸º)
            if retweet_ratio > 0.8:  # å¼‚å¸¸é«˜è½¬å‘æ¯”ä¾‹
                quality = 0.3
            elif like_ratio < 0.3:  # å¼‚å¸¸ä½ç‚¹èµæ¯”ä¾‹
                quality = 0.5
            else:
                quality = 1.0
                
        total_quality += quality
    
    return total_quality / len(tweets) if tweets else 0
```

### ä¼ æ’­é€Ÿåº¦è®¡ç®—å¼•æ“

**å®æ—¶ä¼ æ’­åˆ†æ**:

```python
def calculate_propagation_speed(topic_id: str, timeframe: str) -> float:
    # è·å–æ—¶é—´çª—å£
    if timeframe == "5m":
        window_minutes = 5
    elif timeframe == "1h":
        window_minutes = 60
    elif timeframe == "4h":
        window_minutes = 240
    else:
        raise ValueError("Invalid timeframe")
    
    # è·å–è¯é¢˜åœ¨æ—¶é—´çª—å£å†…çš„æ¨æ–‡
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(minutes=window_minutes)
    
    topic_tweets = get_topic_tweets_in_range(topic_id, start_time, end_time)
    
    if len(topic_tweets) < 2:
        return 0.0
    
    # æŒ‰æ—¶é—´æ’åº
    topic_tweets.sort(key=lambda x: x.created_at)
    
    # è®¡ç®—ä¼ æ’­é€Ÿåº¦æŒ‡æ ‡
    unique_users = set(t.user_id for t in topic_tweets)
    total_engagement = sum(
        t.like_count + t.retweet_count + t.reply_count 
        for t in topic_tweets
    )
    
    # ä¼ æ’­é€Ÿåº¦ = (å‚ä¸ç”¨æˆ·æ•° * æ€»äº’åŠ¨æ•°) / æ—¶é—´çª—å£(åˆ†é’Ÿ)
    base_speed = (len(unique_users) * total_engagement) / window_minutes
    
    # KOLåŠ é€Ÿå™¨ - KOLå‚ä¸ä¼šæ˜¾è‘—æå‡ä¼ æ’­é€Ÿåº¦
    kol_tweets = [t for t in topic_tweets if is_kol_user(t.user_id)]
    kol_multiplier = 1 + (len(kol_tweets) * 0.5)  # æ¯ä¸ªKOLå‚ä¸+50%
    
    # ç—…æ¯’å¼ä¼ æ’­æ£€æµ‹
    time_intervals = []
    for i in range(1, len(topic_tweets)):
        interval = (topic_tweets[i].created_at - topic_tweets[i-1].created_at).seconds / 60
        time_intervals.append(interval)
    
    avg_interval = sum(time_intervals) / len(time_intervals)
    if avg_interval < 1:  # å¹³å‡é—´éš”å°äº1åˆ†é’Ÿ
        viral_multiplier = 2.0
    elif avg_interval < 5:
        viral_multiplier = 1.5
    else:
        viral_multiplier = 1.0
    
    final_speed = base_speed * kol_multiplier * viral_multiplier
    
    return round(final_speed, 2)
```

## Infrastructure and Deployment

### Infrastructure as Code
- **Tool**: Terraform 1.6.6
- **Location**: `infrastructure/terraform/`
- **Approach**: æ¨¡å—åŒ–IaCï¼ŒæŒ‰ç¯å¢ƒåˆ†ç¦»é…ç½®

### Deployment Strategy
- **Strategy**: è“ç»¿éƒ¨ç½² + é‡‘ä¸é›€å‘å¸ƒ
- **CI/CD Platform**: GitHub Actions
- **Pipeline Configuration**: `.github/workflows/`

### Environments
- **Development**: æœ¬åœ°å¼€å‘ç¯å¢ƒ - Docker Compose + ç®€åŒ–ç‰ˆæ•°æ®
- **Staging**: é¢„ç”Ÿäº§ç¯å¢ƒ - å®Œæ•´åŠŸèƒ½æµ‹è¯•ï¼ŒçœŸå®æ•°æ®å­é›†
- **Production**: ç”Ÿäº§ç¯å¢ƒ - å¤šåŒºåŸŸéƒ¨ç½²ï¼Œå®Œæ•´ç›‘æ§å‘Šè­¦

### Environment Promotion Flow
```
Development â†’ Staging â†’ Production
     â†‘            â†‘          â†‘
   æœ¬åœ°æµ‹è¯•    é›†æˆæµ‹è¯•    ç”Ÿäº§ç›‘æ§
   å•å…ƒæµ‹è¯•    æ€§èƒ½æµ‹è¯•    å›æ»šå‡†å¤‡
```

### Rollback Strategy
- **Primary Method**: Kubernetesæ»šåŠ¨å›æ»š + è“ç»¿åˆ‡æ¢
- **Trigger Conditions**: é”™è¯¯ç‡>5%, å“åº”æ—¶é—´>1s, å¥åº·æ£€æŸ¥å¤±è´¥
- **Recovery Time Objective**: < 5åˆ†é’Ÿ

## Error Handling Strategy

### General Approach
- **Error Model**: ç»“æ„åŒ–é”™è¯¯å“åº”ï¼Œç»Ÿä¸€é”™è¯¯ç ä½“ç³»
- **Exception Hierarchy**: ä¸šåŠ¡å¼‚å¸¸ > æŠ€æœ¯å¼‚å¸¸ > ç³»ç»Ÿå¼‚å¸¸
- **Error Propagation**: å‘ä¸Šä¼ æ’­ï¼Œåœ¨è¾¹ç•Œå±‚è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½ä¿¡æ¯

### Logging Standards
- **Library**: Python logging + Go logrus
- **Format**: JSONç»“æ„åŒ–æ—¥å¿—
- **Levels**: DEBUG < INFO < WARN < ERROR < FATAL
- **Required Context**:
  - Correlation ID: UUID v4æ ¼å¼ï¼Œå…¨é“¾è·¯è¿½è¸ª
  - Service Context: æœåŠ¡åç§°ã€ç‰ˆæœ¬ã€å®ä¾‹ID
  - User Context: API Key hashï¼Œä¸è®°å½•æ•æ„Ÿä¿¡æ¯

### Error Handling Patterns

#### External API Errors
- **Retry Policy**: æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§é‡è¯•3æ¬¡
- **Circuit Breaker**: é”™è¯¯ç‡>50%æ—¶å¼€å¯ï¼Œ60sæ¢å¤æ£€æµ‹
- **Timeout Configuration**: Twitter API 30sï¼ŒPrice API 10s
- **Error Translation**: HTTPçŠ¶æ€ç æ˜ å°„ä¸ºå†…éƒ¨é”™è¯¯ç 

#### Business Logic Errors  
- **Custom Exceptions**: InvalidKOLException, InsufficientDataException
- **User-Facing Errors**: ç»Ÿä¸€æ ¼å¼ {"code": "E001", "message": "æè¿°"}
- **Error Codes**: æŒ‰æ¨¡å—åˆ†ç±» (T001-æ¨æ–‡, K001-KOL, M001-æŒ‡æ ‡)

#### Data Consistency
- **Transaction Strategy**: SAGAæ¨¡å¼å¤„ç†è·¨æœåŠ¡äº‹åŠ¡
- **Compensation Logic**: å„æœåŠ¡å®ç°è¡¥å¿æ“ä½œå›æ»šçŠ¶æ€
- **Idempotency**: æ‰€æœ‰å†™æ“ä½œæ”¯æŒå¹‚ç­‰ï¼Œä½¿ç”¨è¯·æ±‚IDå»é‡

## Coding Standards

### Core Standards
- **Languages & Runtimes**: Python 3.11.7, Go 1.21.5 (ä¸¥æ ¼ç‰ˆæœ¬æ§åˆ¶)
- **Style & Linting**: Python (black + flake8), Go (gofmt + golint)
- **Test Organization**: æµ‹è¯•æ–‡ä»¶ä¸æºæ–‡ä»¶åŒç›®å½•ï¼Œ_test.py/_test.goåç¼€

### Critical Rules
- **æ—¥å¿—è§„èŒƒ**: ç”Ÿäº§ä»£ç ç¦ç”¨print()ï¼Œå¿…é¡»ä½¿ç”¨logger
- **APIå“åº”æ ¼å¼**: æ‰€æœ‰APIå¿…é¡»ä½¿ç”¨æ ‡å‡†ResponseWrapperç±»å‹
- **æ•°æ®åº“è®¿é—®**: å¿…é¡»ä½¿ç”¨Repositoryæ¨¡å¼ï¼Œç¦æ­¢ç›´æ¥ORMæŸ¥è¯¢
- **å¯†é’¥ç®¡ç†**: ç¦æ­¢ç¡¬ç¼–ç ä»»ä½•å¯†é’¥ï¼Œå¿…é¡»é€šè¿‡é…ç½®æœåŠ¡è·å–
- **é”™è¯¯å¤„ç†**: å¤–éƒ¨APIè°ƒç”¨å¿…é¡»åŒ…å«è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
- **å¹¶å‘å®‰å…¨**: å…±äº«çŠ¶æ€è®¿é—®å¿…é¡»ä½¿ç”¨é”æˆ–åŸå­æ“ä½œ

## Test Strategy and Standards

### Testing Philosophy
- **Approach**: TDDä¼˜å…ˆï¼Œæµ‹è¯•é‡‘å­—å¡”ç»“æ„
- **Coverage Goals**: å•å…ƒæµ‹è¯•>80%ï¼Œé›†æˆæµ‹è¯•>70%
- **Test Pyramid**: 70%å•å…ƒæµ‹è¯•ï¼Œ20%é›†æˆæµ‹è¯•ï¼Œ10%ç«¯åˆ°ç«¯æµ‹è¯•

### Test Types and Organization

#### Unit Tests
- **Framework**: Python pytest 7.4.3, Go testing + testify
- **File Convention**: test_*.py, *_test.go
- **Location**: ä¸æºæ–‡ä»¶åŒç›®å½•
- **Mocking Library**: Python unittest.mock, Go gomock
- **Coverage Requirement**: æ¯ä¸ªå…¬å¼€æ–¹æ³•å¿…é¡»æµ‹è¯•

**AI Agent Requirements**:
- ä¸ºæ‰€æœ‰å…¬å¼€æ–¹æ³•ç”Ÿæˆæµ‹è¯•
- è¦†ç›–è¾¹ç•Œæ¡ä»¶å’Œé”™è¯¯æƒ…å†µ
- éµå¾ªAAAæ¨¡å¼ (Arrange, Act, Assert)
- Mockæ‰€æœ‰å¤–éƒ¨ä¾èµ–

#### Integration Tests
- **Scope**: æœåŠ¡é—´APIè°ƒç”¨ï¼Œæ•°æ®åº“æ“ä½œï¼Œæ¶ˆæ¯é˜Ÿåˆ—
- **Location**: tests/integration/
- **Test Infrastructure**:
  - **PostgreSQL**: Testcontainerså¯åŠ¨çœŸå®æ•°æ®åº“
  - **Redis**: åµŒå…¥å¼Rediså®ä¾‹
  - **Kafka**: Embedded Kafka for tests

#### End-to-End Tests  
- **Framework**: Python pytest + requests
- **Scope**: å®Œæ•´ç”¨æˆ·åœºæ™¯ï¼Œè·¨æœåŠ¡æ•°æ®æµ
- **Environment**: ç‹¬ç«‹æµ‹è¯•ç¯å¢ƒ
- **Test Data**: å›ºå®šæµ‹è¯•æ•°æ®é›†ï¼Œè‡ªåŠ¨æ¸…ç†

### Test Data Management
- **Strategy**: Factoryæ¨¡å¼ + å›ºå®šFixture
- **Fixtures**: tests/fixtures/ç›®å½•
- **Factories**: ä½¿ç”¨factory_boyç”Ÿæˆæµ‹è¯•æ•°æ®
- **Cleanup**: æµ‹è¯•åè‡ªåŠ¨æ¸…ç†ï¼Œéš”ç¦»æ•°æ®æ±¡æŸ“

### Continuous Testing
- **CI Integration**: PRæ£€æŸ¥ > é›†æˆæµ‹è¯• > éƒ¨ç½²æµ‹è¯•
- **Performance Tests**: Locustè´Ÿè½½æµ‹è¯•ï¼Œæ¯æ—¥è¿è¡Œ
- **Security Tests**: SAST (SonarQube) + DAST (OWASP ZAP)

## Security

### Input Validation
- **Validation Library**: Python Pydantic, Go validator
- **Validation Location**: APIè¾¹ç•Œå±‚ç»Ÿä¸€éªŒè¯
- **Required Rules**:
  - æ‰€æœ‰å¤–éƒ¨è¾“å…¥å¿…é¡»éªŒè¯
  - APIè¾¹ç•ŒéªŒè¯ä¼˜äºä¸šåŠ¡é€»è¾‘éªŒè¯  
  - ç™½åå•æ–¹å¼ä¼˜äºé»‘åå•

### Authentication & Authorization
- **Auth Method**: JWT Token + API KeyåŒé‡è®¤è¯
- **Session Management**: æ— çŠ¶æ€JWTï¼ŒRediså­˜å‚¨æ’¤é”€åˆ—è¡¨
- **Required Patterns**:
  - API Keyç”¨äºæœåŠ¡è¯†åˆ«å’Œè®¡è´¹
  - JWT Tokenç”¨äºç”¨æˆ·ä¼šè¯å’Œæƒé™

### Secrets Management
- **Development**: .envæ–‡ä»¶ + git-secretåŠ å¯†
- **Production**: AWS Secrets Manager
- **Code Requirements**:
  - ç»ä¸ç¡¬ç¼–ç å¯†é’¥
  - ä»…é€šè¿‡é…ç½®æœåŠ¡è®¿é—®
  - æ—¥å¿—å’Œé”™è¯¯æ¶ˆæ¯ä¸­ä¸åŒ…å«å¯†é’¥

### API Security  
- **Rate Limiting**: Kong Gatewayå®ç°ï¼ŒæŒ‰API Keyé™æµ
- **CORS Policy**: ä¸¥æ ¼åŸŸåç™½åå•
- **Security Headers**: HSTS, CSP, X-Frame-Optionsç­‰
- **HTTPS Enforcement**: å…¨ç«™HTTPSï¼ŒHTTPè‡ªåŠ¨é‡å®šå‘

### Data Protection
- **Encryption at Rest**: AES-256æ•°æ®åº“åŠ å¯†
- **Encryption in Transit**: TLS 1.3å¼ºåˆ¶åŠ å¯†
- **PII Handling**: ç”¨æˆ·æ•°æ®è„±æ•ï¼Œæœ€å°åŒ–æ”¶é›†
- **Logging Restrictions**: ç¦æ­¢è®°å½•å¯†é’¥ã€ä¸ªäººä¿¡æ¯ã€å®Œæ•´IP

### Dependency Security
- **Scanning Tool**: Snyk + GitHub Dependabot
- **Update Policy**: å®‰å…¨è¡¥ä¸7å¤©å†…æ›´æ–°
- **Approval Process**: æ–°ä¾èµ–éœ€æ¶æ„å¸ˆå®¡æ‰¹

### Security Testing
- **SAST Tool**: SonarQubeä»£ç é™æ€åˆ†æ
- **DAST Tool**: OWASP ZAPåŠ¨æ€å®‰å…¨æµ‹è¯•  
- **Penetration Testing**: å­£åº¦ç¬¬ä¸‰æ–¹æ¸—é€æµ‹è¯•

---

ğŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>