"""
Gemini API å®¢æˆ·ç«¯
ç”¨äºè¯é¢˜åˆ†æã€å†…å®¹ç”Ÿæˆå’Œæƒ…æ„Ÿåˆ†æ
"""
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
import time

from google import genai

from ..utils.config_manager import config


class ChatGPTClient:
    """Gemini APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        """åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯"""
        self.chatgpt_config = config.get('chatgpt', {})
        self.api_key = self.chatgpt_config.get('api_key', '')
        self.model = self.chatgpt_config.get('model', 'gemini-2.5-flash-lite')
        self.timeout = self.chatgpt_config.get('timeout', 30)
        self.max_retries = self.chatgpt_config.get('max_retries', 3)
        self.retry_delay = self.chatgpt_config.get('retry_delay', 2)
        
        # å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œé¿å…æ¨¡å—å¯¼å…¥æ—¶çš„é—®é¢˜
        self.client = None
        
        self.logger = logging.getLogger(__name__)
        
        # è¯·æ±‚ç»Ÿè®¡
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0
        
        # æ‰¹å¤„ç†ä¼˜åŒ–é…ç½®
        batch_config = self.chatgpt_config.get('batch_processing', {})
        opt_config = self.chatgpt_config.get('optimization', {})
        
        self.enable_batch_consolidation = opt_config.get('enable_batch_consolidation', True)
        self.max_prompt_tokens = opt_config.get('max_prompt_tokens', 3000)
        self.content_merge_threshold = batch_config.get('content_merge_threshold', 2000)
        
        # å“åº”ç¼“å­˜
        self.enable_response_caching = opt_config.get('enable_response_caching', True)
        self.response_cache = {} if self.enable_response_caching else None
        self.cache_ttl_hours = opt_config.get('cache_ttl_hours', 24)
        
        # æ‰“å°æ¨¡å‹é…ç½®ä¿¡æ¯
        self.logger.info(f"ğŸ¤– Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ“‹ ä½¿ç”¨æ¨¡å‹: {self.model}")
        self.logger.info(f"ğŸ”‘ APIå¯†é’¥: {self.api_key[:10]}...{self.api_key[-4:] if len(self.api_key) > 14 else '*' * 4}")
        self.logger.info(f"âš™ï¸  è¶…æ—¶è®¾ç½®: {self.timeout}ç§’ï¼Œæœ€å¤§é‡è¯•: {self.max_retries}æ¬¡")
    
    def _get_client(self):
        """è·å–Geminiå®¢æˆ·ç«¯ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if self.client is None:
            self.client = genai.Client(api_key=self.api_key)
        return self.client
    
    def _make_request(self, messages: List[Dict[str, str]], **kwargs) -> Optional[str]:
        """
        å‘èµ·Gemini APIè¯·æ±‚ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtemperature, max_tokensç­‰ï¼ŒGeminiå¯èƒ½ä¸æ”¯æŒæ‰€æœ‰å‚æ•°ï¼‰
            
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹æˆ–None
        """
        for attempt in range(self.max_retries):
            try:
                self.logger.debug(f"å‘èµ·Geminiè¯·æ±‚ (å°è¯• {attempt + 1}/{self.max_retries})")
                
                # Gemini APIè°ƒç”¨
                client = self._get_client()
                chat = client.chats.create(model=self.model)
                
                # å°†messagesè½¬æ¢ä¸ºGeminiæ ¼å¼
                # Geminiä½¿ç”¨å•æ¡æ¶ˆæ¯ï¼Œéœ€è¦åˆå¹¶systemå’Œuseræ¶ˆæ¯
                system_content = ""
                user_content = ""
                for msg in messages:
                    role = msg.get('role', 'user')
                    content = msg.get('content', '')
                    if role == 'system':
                        system_content = content
                    elif role == 'user':
                        if user_content:
                            user_content += "\n\n" + content
                        else:
                            user_content = content
                
                # åˆå¹¶systemå’Œuserå†…å®¹
                if system_content:
                    prompt = f"{system_content}\n\n{user_content}"
                else:
                    prompt = user_content
                
                response = chat.send_message(prompt)
                content = response.text
                
                self.request_count += 1
                self.success_count += 1
                
                self.logger.debug(f"Geminiè¯·æ±‚æˆåŠŸï¼Œç”Ÿæˆå†…å®¹é•¿åº¦: {len(content)}")
                
                return content
                
            except Exception as e:
                error_type = type(e).__name__
                error_str = str(e).lower()
                
                # å¤„ç†é€Ÿç‡é™åˆ¶é”™è¯¯
                if 'RateLimitError' in error_type or 'rate_limit' in error_str or '429' in error_str or 'quota' in error_str:
                    self.logger.warning(f"Geminié€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•")
                    self.logger.error(f"RateLimitErrorè¯¦æƒ…: {str(e)}")
                    time.sleep(self.retry_delay * (attempt + 1))
                    continue
                
                # å¤„ç†APIé”™è¯¯
                if 'APIError' in error_type or 'api' in error_str or '400' in error_str or '500' in error_str:
                    self.logger.error(f"Gemini APIé”™è¯¯: {e}")
                    if attempt < self.max_retries - 1:
                        time.sleep(self.retry_delay)
                        continue
                    else:
                        break
                
                # å…¶ä»–å¼‚å¸¸
                self.logger.error(f"Geminiè¯·æ±‚å¼‚å¸¸: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    break
        
        self.request_count += 1
        self.error_count += 1
        return None
    
    def extract_topic_from_tweet(self, tweet_content: str) -> Optional[Dict[str, str]]:
        """
        ä»æ¨æ–‡ä¸­æå–è¯é¢˜ä¿¡æ¯
        
        Args:
            tweet_content: æ¨æ–‡å†…å®¹
            
        Returns:
            è¯é¢˜ä¿¡æ¯å­—å…¸ {"topic_name": "...", "brief": "..."}
        """
        try:
            prompt = f"""
            Please analyze the following cryptocurrency-related tweet and extract the main topic:

            Tweet content: {tweet_content}

            Please provide:
            1. topic_name: Concise topic name (5-15 words, highlighting the core theme)
            2. brief: Brief topic description (20-50 words, explaining topic content and background)

            Notes:
            - If the tweet is pure advertising or spam content, return "Invalid Topic"
            - Focus on cryptocurrency, blockchain, DeFi, NFT and related themes
            - Topic name should be specific and meaningful

            Please return in JSON format:
            {{"topic_name": "Topic Name", "brief": "Topic Description"}}
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency market analyst skilled in identifying and analyzing cryptocurrency-related topics."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.3,
                max_tokens=200
            )
            
            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()

                    # å°è¯•è§£æJSONå“åº”
                    result = json.loads(cleaned_response)

                    # éªŒè¯è¿”å›çš„æ•°æ®
                    if isinstance(result, dict) and 'topic_name' in result and 'brief' in result:
                        topic_name = result['topic_name'].strip()
                        brief = result['brief'].strip()
                        
                        # è¿‡æ»¤æ— æ•ˆè¯é¢˜
                        if topic_name == "Invalid Topic" or not topic_name:
                            return None
                            
                        return {
                            "topic_name": topic_name,
                            "brief": brief
                        }
                        
                except json.JSONDecodeError:
                    self.logger.warning(f"ChatGPTè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {response}")
                    return None
            
            return None
            
        except Exception as e:
            self.logger.error(f"æå–è¯é¢˜å¤±è´¥: {e}")
            return None
    
    def analyze_sentiment(self, text: str) -> Optional[Dict[str, Any]]:
        """
        åˆ†ææ–‡æœ¬æƒ…æ„Ÿ
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            æƒ…æ„Ÿåˆ†æç»“æœ {"sentiment": "positive/negative/neutral", "confidence": 0.0-1.0, "score": 0-100}
        """
        try:
            prompt = f"""
            Please analyze the sentiment tendency of the following cryptocurrency-related text:

            Text content: {text}

            Please evaluate:
            1. sentiment: Sentiment direction (positive/negative/neutral)
            2. confidence: Confidence level (0.0-1.0, indicating certainty of judgment)
            3. reasoning: Reasoning for judgment (brief explanation)

            Notes:
            - Focus on cryptocurrency market sentiment
            - Consider the meaning of technical terms and slang
            - positive: bullish, optimistic, supportive
            - negative: bearish, pessimistic, critical
            - neutral: neutral, objective analysis

            Please return in JSON format:
            {{"sentiment": "positive", "confidence": 0.8, "reasoning": "Reasoning"}}
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency sentiment analyst skilled in understanding market sentiment and investor psychology."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.2,
                max_tokens=150
            )
            
            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()

                    # å°è¯•è§£æJSONå“åº”
                    result = json.loads(cleaned_response)

                    if isinstance(result, dict) and 'sentiment' in result and 'confidence' in result:
                        sentiment = result['sentiment']
                        confidence = float(result['confidence'])
                        
                        # è®¡ç®—0-100åˆ†æ•°
                        if sentiment == "positive":
                            score = 50 + (confidence * 50)
                        elif sentiment == "negative":
                            score = 50 - (confidence * 50)
                        else:  # neutral
                            score = 50
                        
                        return {
                            "sentiment": sentiment,
                            "confidence": confidence,
                            "score": round(score, 1),
                            "reasoning": result.get("reasoning", "")
                        }
                        
                except (json.JSONDecodeError, ValueError, TypeError):
                    self.logger.warning(f"ChatGPTæƒ…æ„Ÿåˆ†æè¿”å›æ ¼å¼é”™è¯¯: {response}")
                    return None
            
            return None
            
        except Exception as e:
            self.logger.error(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_topic_summary(self, topic_name: str, related_tweets: List[str], 
                              existing_summary: str = None) -> Optional[str]:
        """
        ç”Ÿæˆè¯é¢˜æ€»ç»“ï¼ˆä½¿ç”¨æ–°çš„KOLè§‚ç‚¹åˆ†ææ ¼å¼ï¼‰
        
        Args:
            topic_name: è¯é¢˜åç§°
            related_tweets: ç›¸å…³æ¨æ–‡åˆ—è¡¨
            existing_summary: å·²æœ‰çš„æ€»ç»“ï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
            
        Returns:
            ç”Ÿæˆçš„è¯é¢˜æ€»ç»“ï¼ˆJSONæ ¼å¼çš„KOLè§‚ç‚¹åˆ†æï¼‰
        """
        try:
            # é™åˆ¶æ¨æ–‡æ•°é‡ä»¥æ§åˆ¶tokenä½¿ç”¨
            tweets_sample = related_tweets[:15]  # å¢åŠ æ ·æœ¬æ•°é‡ä»¥è·å¾—æ›´å¥½çš„è§‚ç‚¹åˆ†æ
            
            # æ„å»ºæ¨æ–‡æ•°æ®ï¼ˆéœ€è¦æ›´å¤šä¿¡æ¯æ¥æ”¯æŒæ–°æ ¼å¼ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦é‡æ„è°ƒç”¨æ–¹æ³•æ¥ä¼ é€’æ›´å¤šæ•°æ®
            return self._generate_kol_viewpoints_summary(topic_name, tweets_sample, existing_summary)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè¯é¢˜æ€»ç»“å¤±è´¥: {e}")
            return None
    
    def _generate_kol_viewpoints_summary(self, topic_name: str, tweets: List[str], existing_summary: str = None) -> Optional[str]:
        """
        ä½¿ç”¨æ–°çš„KOLè§‚ç‚¹åˆ†æpromptç”Ÿæˆè¯é¢˜æ€»ç»“
        """
        try:
            # æ„å»ºæ¨æ–‡å†…å®¹
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets])
            
            # ä½¿ç”¨æ–°çš„ä¸“ä¸šprompt
            system_prompt = "You are an experienced web3 media editor, skilled at quickly organizing and summarizing KOL opinions from crypto-related trending topics."
            
            if existing_summary:
                user_prompt = f"""
Please update the KOL opinion summary for topic "{topic_name}", combining new tweet content:

Existing Summary:
{existing_summary}

New Tweet Content:
{tweets_text}

Please update the KOL consensus opinions in the following JSON format (sorted by number of KOLs holding the same opinion, output top 3 opinions):
{{
  "topic_id": "{topic_name}",
  "summary": [
    {{
      "viewpoint": "Opinion summary",
      "related_tweets": ["Tweet content excerpts reflecting this opinion"]
    }}
  ]
}}

Output only the above JSON without additional explanation.
                """
            else:
                user_prompt = f"""
You will receive multiple tweets about topic "{topic_name}" in the following format:

Related Tweets:
{tweets_text}

Please summarize the consensus opinions of KOLs on this event (sorted by number of KOLs holding the same opinion, output top 3 opinions, can be less than 3), in the following JSON format:
{{
  "topic_id": "{topic_name}",
  "summary": [
    {{
      "viewpoint": "Opinion summary",
      "related_tweets": ["Tweet content excerpts reflecting this opinion"]
    }}
  ]
}}

Output only the above JSON without additional explanation.
                """
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.3,  # é™ä½temperatureä»¥è·å¾—æ›´ä¸€è‡´çš„JSONè¾“å‡º
                max_tokens=500   # å¢åŠ tokené™åˆ¶ä»¥æ”¯æŒæ›´è¯¦ç»†çš„åˆ†æ
            )
            
            if response:
                return response.strip()
            
            return None
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆKOLè§‚ç‚¹åˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_kol_consensus_summary(self, topic_data: Dict[str, Any]) -> Optional[str]:
        """
        æ ¹æ®å®Œæ•´çš„è¯é¢˜æ•°æ®ç”ŸæˆKOLå…±è¯†è§‚ç‚¹æ€»ç»“
        
        Args:
            topic_data: åŒ…å«è¯é¢˜å’Œç›¸å…³æ¨æ–‡çš„å®Œæ•´æ•°æ®
            
        Returns:
            KOLè§‚ç‚¹å…±è¯†JSONæ ¼å¼çš„æ€»ç»“
        """
        try:
            import json
            
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„web3åª’ä½“ç¼–è¾‘ï¼Œæ“…é•¿å¿«é€Ÿä»Cryptoç›¸å…³çš„çƒ­é—¨è¯é¢˜ä¸­æ¢³ç†å¹¶æ€»ç»“æ¸…æ¥šKOLä»¬å‘è¡¨çš„è§‚ç‚¹ã€‚"
            
            # æ„å»ºè¾“å…¥æ•°æ®ç»“æ„
            input_data = {
                "topic_id": topic_data.get('topic_id', ''),
                "topic_name": topic_data.get('topic_name', ''),
                "category": topic_data.get('category', 'crypto'),
                "key_entities": topic_data.get('key_entities', []),
                "timestamp": topic_data.get('timestamp', ''),
                "brief": topic_data.get('brief', ''),
                "related_tweets": []
            }
            
            # é™åˆ¶æ¨æ–‡æ•°é‡å¹¶æ„å»ºæ¨æ–‡æ•°æ®
            related_tweets = topic_data.get('related_tweets', [])[:20]
            for tweet in related_tweets:
                input_data["related_tweets"].append({
                    "id_str": tweet.get('id_str', ''),
                    "kol_id": tweet.get('kol_id', ''),
                    "full_text": tweet.get('full_text', '')
                })
            
            # ä½¿ç”¨JSONåºåˆ—åŒ–æ„å»ºç”¨æˆ·æç¤º
            user_prompt = f"""You will receive multiple KOL tweets about an event in the following format:
{json.dumps(input_data, ensure_ascii=False, indent=2)}

Please summarize the consensus opinions of KOLs on this event (sorted by number of KOLs holding the same opinion, output top 3 opinions, can be less than 3), in the following JSON format:
{{
  "topic_id": Event ID,
  "summary": [
    {{
      "viewpoint": Opinion summary,
      "related_tweets": [Tweet IDs reflecting this opinion, may be multiple],
    }}
  ]
}}

Output only the above JSON without additional explanation."""
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.2,
                max_tokens=800
            )
            
            return response.strip() if response else None
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆKOLå…±è¯†è§‚ç‚¹æ€»ç»“å¤±è´¥: {e}")
            return None
    
    def analyze_mob_opinion_direction(self, tweets: List[str]) -> Optional[str]:
        """
        åˆ†ææ•£æˆ·æ•´ä½“è§‚ç‚¹æ–¹å‘
        
        Args:
            tweets: æ¨æ–‡åˆ—è¡¨
            
        Returns:
            è§‚ç‚¹æ–¹å‘ positive/negative/neutral
        """
        try:
            # é™åˆ¶æ¨æ–‡æ•°é‡
            tweets_sample = tweets[:20]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])
            
            prompt = f"""
            Please analyze the overall opinion direction of retail investors in the following tweets:

            Tweet content:
            {tweets_text}

            Please evaluate the overall sentiment tendency of retail investors:
            - positive: Overall optimistic, bullish, supportive
            - negative: Overall pessimistic, bearish, critical
            - neutral: Divided opinions or neutral

            Return only one word: positive, negative or neutral
            """
            
            messages = [
                {"role": "system", "content": "You are a professional market sentiment analyst skilled in analyzing collective emotions of retail investors."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.1,
                max_tokens=10
            )
            
            if response:
                direction = response.strip().lower()
                if direction in ['positive', 'negative', 'neutral']:
                    return direction
            
            return 'neutral'  # é»˜è®¤è¿”å›ä¸­æ€§
            
        except Exception as e:
            self.logger.error(f"åˆ†ææ•£æˆ·è§‚ç‚¹æ–¹å‘å¤±è´¥: {e}")
            return 'neutral'
    
    def batch_analyze_tweets(self, tweets: List[str]) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†ææ¨æ–‡
        
        Args:
            tweets: æ¨æ–‡åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, tweet in enumerate(tweets):
            self.logger.info(f"åˆ†ææ¨æ–‡ {i+1}/{len(tweets)}")
            
            # æå–è¯é¢˜
            topic_info = self.extract_topic_from_tweet(tweet)
            
            # åˆ†ææƒ…æ„Ÿ
            sentiment_info = self.analyze_sentiment(tweet)
            
            result = {
                "tweet_content": tweet,
                "topic_info": topic_info,
                "sentiment_info": sentiment_info
            }
            
            results.append(result)
            
            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(0.5)
        
        return results
    
    def batch_extract_topics_from_tweets(self, tweets: List[str]) -> List[Optional[Dict[str, str]]]:
        """
        æ™ºèƒ½æ‰¹é‡è¯é¢˜æå–ï¼Œä¼˜åŒ–tokenä½¿ç”¨
        
        Args:
            tweets: æ¨æ–‡å†…å®¹åˆ—è¡¨
            
        Returns:
            è¯é¢˜ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”è¾“å…¥æ¨æ–‡çš„è¯é¢˜ä¿¡æ¯
        """
        if not tweets:
            return []
            
        # 1. æ£€æŸ¥ç¼“å­˜
        cached_results = []
        uncached_tweets = []
        uncached_indices = []
        
        for i, tweet in enumerate(tweets):
            cached_result = self._get_cached_response(tweet, 'topic_extraction')
            if cached_result:
                cached_results.append((i, cached_result))
            else:
                uncached_tweets.append(tweet)
                uncached_indices.append(i)
        
        # 2. å¦‚æœæ²¡æœ‰æœªç¼“å­˜çš„æ¨æ–‡ï¼Œç›´æ¥è¿”å›
        if not uncached_tweets:
            results = [None] * len(tweets)
            for idx, result in cached_results:
                results[idx] = result
            return results
        
        # 3. å†…å®¹å»é‡å’Œåˆå¹¶
        if self.enable_batch_consolidation and len(uncached_tweets) > 1:
            batch_results = self._batch_extract_topics_consolidated(uncached_tweets)
        else:
            # é€ä¸ªå¤„ç†ï¼ˆæ—§æ–¹å¼ï¼‰
            batch_results = []
            for tweet in uncached_tweets:
                result = self.extract_topic_from_tweet(tweet)
                batch_results.append(result)
        
        # 4. ç¼“å­˜ç»“æœ
        for i, result in enumerate(batch_results):
            if result and self.enable_response_caching:
                self._cache_response(uncached_tweets[i], 'topic_extraction', result)
        
        # 5. åˆå¹¶ç¼“å­˜å’Œæ–°ç»“æœ
        final_results = [None] * len(tweets)
        for idx, result in cached_results:
            final_results[idx] = result
        for i, idx in enumerate(uncached_indices):
            final_results[idx] = batch_results[i] if i < len(batch_results) else None
            
        return final_results
    
    def _batch_extract_topics_consolidated(self, tweets: List[str]) -> List[Optional[Dict[str, str]]]:
        """
        åˆå¹¶å†…å®¹è¿›è¡Œæ‰¹é‡è¯é¢˜æå–ï¼Œå‡å°‘APIè°ƒç”¨
        """
        try:
            # åˆå¹¶ç›¸ä¼¼å†…å®¹
            content_groups = self._group_similar_content(tweets)
            
            results = [None] * len(tweets)
            
            for group_indices, group_tweets in content_groups:
                if len(group_tweets) == 1:
                    # å•æ¡æ¨æ–‡
                    result = self.extract_topic_from_tweet(group_tweets[0])
                    results[group_indices[0]] = result
                else:
                    # æ‰¹é‡å¤„ç†
                    batch_result = self._extract_topics_from_merged_content(group_tweets)
                    # å°†ç»“æœåˆ†é…ç»™ç»„å†…æ‰€æœ‰æ¨æ–‡
                    for idx in group_indices:
                        results[idx] = batch_result
            
            return results
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡è¯é¢˜æå–å¤±è´¥: {e}")
            # å›é€€åˆ°é€ä¸ªå¤„ç†
            return [self.extract_topic_from_tweet(tweet) for tweet in tweets]
    
    def _group_similar_content(self, tweets: List[str]) -> List[Tuple[List[int], List[str]]]:
        """
        åŸºäºå†…å®¹ç›¸ä¼¼åº¦å°†æ¨æ–‡åˆ†ç»„
        """
        import hashlib
        
        groups = []
        processed = set()
        
        for i, tweet in enumerate(tweets):
            if i in processed:
                continue
                
            # ç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥ - åŸºäºå…³é”®è¯
            current_group_indices = [i]
            current_group_tweets = [tweet]
            processed.add(i)
            
            tweet_keywords = set(tweet.lower().split())
            
            # æŸ¥æ‰¾ç›¸ä¼¼æ¨æ–‡
            for j, other_tweet in enumerate(tweets[i+1:], i+1):
                if j in processed:
                    continue
                    
                other_keywords = set(other_tweet.lower().split())
                # è®¡ç®—Jaccardç›¸ä¼¼åº¦
                intersection = tweet_keywords & other_keywords
                union = tweet_keywords | other_keywords
                similarity = len(intersection) / len(union) if union else 0
                
                if similarity > 0.3:  # 30%ç›¸ä¼¼åº¦é˜ˆå€¼
                    current_group_indices.append(j)
                    current_group_tweets.append(other_tweet)
                    processed.add(j)
            
            groups.append((current_group_indices, current_group_tweets))
        
        return groups
    
    def _extract_topics_from_merged_content(self, tweets: List[str]) -> Optional[Dict[str, str]]:
        """
        ä»åˆå¹¶çš„æ¨æ–‡å†…å®¹ä¸­æå–ä¸»è¦è¯é¢˜
        """
        try:
            # åˆå¹¶å†…å®¹ï¼Œé™åˆ¶é•¿åº¦
            merged_content = "\n---\n".join(tweets[:5])  # æœ€å¤š5æ¡æ¨æ–‡
            if len(merged_content) > self.content_merge_threshold:
                merged_content = merged_content[:self.content_merge_threshold] + "..."

            prompt = f"""
Analyze the following related tweets and extract the main topic being discussed:

Tweet content:
{merged_content}

Please identify:
1. topic_name: Main topic name (5-15 words, highlighting the core theme)
2. brief: Brief topic description (20-50 words, explaining topic content and background in English)

IMPORTANT: Both topic_name and brief MUST be in English.

Return format:
{{
  "topic_name": "Topic Name",
  "brief": "Brief Description"
}}
            """

            messages = [
                {"role": "system", "content": "You are a professional social media content analyst skilled in extracting core topics from multiple tweets. Always respond in English."},
                {"role": "user", "content": prompt}
            ]

            response = self._make_request(messages, temperature=0.3, max_tokens=200)

            if response:
                # è§£æJSONå“åº”
                import json
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = response[json_start:json_end]
                    result = json.loads(json_str)
                    return result

            return None

        except Exception as e:
            self.logger.error(f"åˆå¹¶å†…å®¹è¯é¢˜æå–å¤±è´¥: {e}")
            return None
    
    def _get_cached_response(self, content: str, operation: str) -> Optional[Dict[str, Any]]:
        """
        è·å–ç¼“å­˜çš„å“åº”
        """
        if not self.enable_response_caching or not self.response_cache:
            return None
            
        cache_key = f"{operation}:{hash(content)}"
        cached_item = self.response_cache.get(cache_key)
        
        if cached_item:
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            from datetime import datetime, timedelta
            if datetime.now() - cached_item['timestamp'] < timedelta(hours=self.cache_ttl_hours):
                return cached_item['result']
            else:
                # åˆ é™¤è¿‡æœŸç¼“å­˜
                del self.response_cache[cache_key]
        
        return None
    
    def _cache_response(self, content: str, operation: str, result: Dict[str, Any]):
        """
        ç¼“å­˜å“åº”ç»“æœ
        """
        if not self.enable_response_caching or not self.response_cache:
            return
            
        from datetime import datetime
        cache_key = f"{operation}:{hash(content)}"
        self.response_cache[cache_key] = {
            'result': result,
            'timestamp': datetime.now()
        }
        
        # é™åˆ¶ç¼“å­˜å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
        if len(self.response_cache) > 1000:
            # åˆ é™¤æœ€æ—§çš„20%ç¼“å­˜é¡¹
            oldest_keys = sorted(self.response_cache.keys(), 
                               key=lambda k: self.response_cache[k]['timestamp'])[:200]
            for key in oldest_keys:
                del self.response_cache[key]
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            'total_requests': self.request_count,
            'success_count': self.success_count,
            'error_count': self.error_count,
            'success_rate': (self.success_count / max(self.request_count, 1)) * 100
        }
    
    def analyze_kol_profile(self, user_info: Dict[str, Any], recent_tweets: List[str]) -> Optional[Dict[str, Any]]:
        """
        åˆ†æç”¨æˆ·çš„KOLç‰¹å¾
        
        Args:
            user_info: ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
            recent_tweets: æœ€è¿‘æ¨æ–‡åˆ—è¡¨
            
        Returns:
            KOLåˆ†æç»“æœ
        """
        try:
            # é™åˆ¶æ¨æ–‡æ•°é‡
            tweets_sample = recent_tweets[:10]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])
            
            # æ£€æµ‹æ¨æ–‡ä¸»è¦è¯­è¨€
            language_tag = self._detect_primary_language(tweets_text)
            
            prompt = f"""
            è¯·åˆ†æä»¥ä¸‹Twitterç”¨æˆ·æ˜¯å¦ä¸ºåŠ å¯†è´§å¸KOLï¼Œå¹¶æä¾›è¯¦ç»†åˆ†æï¼š

            ç”¨æˆ·ä¿¡æ¯:
            - ç”¨æˆ·å: @{user_info.get('screen_name', 'unknown')}
            - æ˜¾ç¤ºå: {user_info.get('name', 'unknown')}
            - ç²‰ä¸æ•°: {user_info.get('followers_count', 0):,}
            - å…³æ³¨æ•°: {user_info.get('friends_count', 0):,}
            - æ¨æ–‡æ•°: {user_info.get('statuses_count', 0):,}
            - ç®€ä»‹: {user_info.get('description', 'N/A')}

            æœ€è¿‘æ¨æ–‡å†…å®¹:
            {tweets_text}

            è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
            1. type: KOLç±»å‹ï¼ˆfounder/influencer/investor/trader/analyst æˆ– "not_kol"ï¼‰
            2. tags: å¤šä¸ªæ ‡ç­¾åˆ—è¡¨ï¼Œå¿…é¡»åŒ…å«è¯­è¨€æ ‡ç­¾ï¼Œæ ¼å¼è¦æ±‚ï¼š
               - è¯­è¨€æ ‡ç­¾ï¼šæ ¹æ®æ¨æ–‡ä¸»è¦è¯­è¨€é€‰æ‹©"English"æˆ–"Chinese"ï¼ˆå¿…é¡»åŒ…å«ï¼‰
               - ä¸“ä¸šæ ‡ç­¾ï¼šåŸºäºæ¨æ–‡å†…å®¹çš„ä¸“ä¸šé¢†åŸŸï¼Œå¦‚BTC/ETH/DeFi/NFT/Meme/AI/Gaming/Layer2/RWAç­‰
               - å¯ä»¥æœ‰2-5ä¸ªæ ‡ç­¾
            3. sentiment: å¸‚åœºæƒ…æ„Ÿå€¾å‘ï¼ˆbullish/bearish/neutralï¼‰
            4. summary: ç®€è¦æ€»ç»“ï¼ˆ50-100å­—ï¼Œæè¿°å…¶è§‚ç‚¹ç‰¹ç‚¹å’Œå½±å“åŠ›ï¼‰
            5. trust_rating: å¯ä¿¡åº¦è¯„çº§ï¼ˆ1-10ï¼ŒåŸºäºä¸“ä¸šåº¦å’Œä¸€è‡´æ€§ï¼‰

            æ³¨æ„ï¼š
            - å¦‚æœä¸æ˜¯åŠ å¯†è´§å¸ç›¸å…³KOLï¼Œtypeè¿”å› "not_kol"
            - tagså¿…é¡»æ˜¯æ•°ç»„æ ¼å¼ï¼Œç¬¬ä¸€ä¸ªæ ‡ç­¾å¿…é¡»æ˜¯è¯­è¨€æ ‡ç­¾
            - ä¸“æ³¨äºåŠ å¯†è´§å¸ã€åŒºå—é“¾é¢†åŸŸçš„å½±å“åŠ›
            - è€ƒè™‘ç²‰ä¸æ•°ã€äº’åŠ¨è´¨é‡å’Œå†…å®¹ä¸“ä¸šåº¦

            è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
            {{
                "type": "influencer",
                "tags": ["{language_tag}", "DeFi", "BTC"],
                "sentiment": "bullish",
                "summary": "ä¸“ä¸šçš„DeFiåˆ†æå¸ˆï¼Œç»å¸¸åˆ†äº«æŠ€æœ¯åˆ†æ...",
                "trust_rating": 8
            }}
            """
            
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸KOLè¯†åˆ«å’Œåˆ†æä¸“å®¶ï¼Œæ“…é•¿è¯„ä¼°å½±å“åŠ›å’Œä¸“ä¸šåº¦ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.3,
                max_tokens=300
            )
            
            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()

                    # å°è¯•è§£æJSONå“åº”
                    result = json.loads(cleaned_response)

                    # éªŒè¯è¿”å›çš„æ•°æ®
                    if isinstance(result, dict) and 'type' in result:
                        # è¿‡æ»¤éKOLç”¨æˆ·
                        if result['type'] == 'not_kol':
                            return None
                        
                        # å¤„ç†tagså­—æ®µï¼šç¡®ä¿è¯­è¨€æ ‡ç­¾å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
                        tags = self._process_kol_tags(result.get('tags', []), language_tag)
                        
                        return {
                            "type": result.get('type'),
                            "tag": tags,  # æ³¨æ„ï¼šè¿™é‡Œè¿”å›çš„æ˜¯æ‹¼æ¥åçš„å­—ç¬¦ä¸²
                            "sentiment": result.get('sentiment'),
                            "summary": result.get('summary'),
                            "trust_rating": result.get('trust_rating', 5)
                        }
                        
                except json.JSONDecodeError:
                    self.logger.warning(f"ChatGPT KOLåˆ†æè¿”å›æ ¼å¼é”™è¯¯: {response}")
                    # ä½¿ç”¨å¤‡ç”¨é€»è¾‘
                    return self._fallback_kol_analysis(user_info, recent_tweets, language_tag)
            
            # ChatGPTåˆ†æå¤±è´¥æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨é€»è¾‘
            return self._fallback_kol_analysis(user_info, recent_tweets, language_tag)
            
        except Exception as e:
            self.logger.error(f"KOLåˆ†æå¤±è´¥: {e}")
            return self._fallback_kol_analysis(user_info, recent_tweets, "English")
    
    def _detect_primary_language(self, text: str) -> str:
        """
        æ£€æµ‹æ–‡æœ¬ä¸»è¦è¯­è¨€
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            è¯­è¨€æ ‡ç­¾ï¼š"Chinese"æˆ–"English"
        """
        try:
            if not text:
                return "English"
            
            # ç®€å•çš„ä¸­æ–‡å­—ç¬¦æ£€æµ‹
            import re
            chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
            total_chars = len(re.findall(r'[\w\u4e00-\u9fff]', text))
            
            if total_chars == 0:
                return "English"
            
            chinese_ratio = len(chinese_chars) / total_chars
            
            # å¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”è¶…è¿‡30%ï¼Œè®¤ä¸ºæ˜¯ä¸­æ–‡å†…å®¹
            if chinese_ratio > 0.3:
                return "Chinese"
            else:
                return "English"
                
        except Exception as e:
            self.logger.warning(f"è¯­è¨€æ£€æµ‹å¤±è´¥: {e}")
            return "English"
    
    def _process_kol_tags(self, raw_tags: List[str], language_tag: str) -> str:
        """
        å¤„ç†KOLæ ‡ç­¾ï¼šç¡®ä¿è¯­è¨€æ ‡ç­¾å­˜åœ¨ï¼Œå¹¶æ‹¼æ¥æˆå­—ç¬¦ä¸²
        
        Args:
            raw_tags: åŸå§‹æ ‡ç­¾åˆ—è¡¨
            language_tag: æ£€æµ‹åˆ°çš„è¯­è¨€æ ‡ç­¾
            
        Returns:
            æ‹¼æ¥åçš„æ ‡ç­¾å­—ç¬¦ä¸²
        """
        try:
            processed_tags = []
            
            # 1. é¦–å…ˆæ·»åŠ è¯­è¨€æ ‡ç­¾ï¼ˆå¿…é¡»çš„ï¼‰
            if language_tag in ["English", "Chinese"]:
                processed_tags.append(language_tag)
            else:
                processed_tags.append("English")  # é»˜è®¤è‹±æ–‡
            
            # 2. æ·»åŠ ä¸“ä¸šæ ‡ç­¾ï¼ˆå»é‡ä¸”è¿‡æ»¤è¯­è¨€æ ‡ç­¾ï¼‰
            if isinstance(raw_tags, list):
                for tag in raw_tags:
                    tag = str(tag).strip()
                    # è·³è¿‡è¯­è¨€æ ‡ç­¾ï¼ˆé¿å…é‡å¤ï¼‰å’Œæ— æ•ˆæ ‡ç­¾
                    if tag not in ["English", "Chinese", "", "Unknown"] and tag not in processed_tags:
                        processed_tags.append(tag)
            
            # 3. å¦‚æœæ²¡æœ‰ä¸“ä¸šæ ‡ç­¾ï¼Œæ·»åŠ é»˜è®¤æ ‡ç­¾
            if len(processed_tags) == 1:  # åªæœ‰è¯­è¨€æ ‡ç­¾
                processed_tags.append("Crypto")  # é»˜è®¤åŠ å¯†è´§å¸æ ‡ç­¾
            
            # 4. é™åˆ¶æ ‡ç­¾æ•°é‡ï¼ˆè¯­è¨€æ ‡ç­¾ + æœ€å¤š4ä¸ªä¸“ä¸šæ ‡ç­¾ï¼‰
            if len(processed_tags) > 5:
                processed_tags = processed_tags[:5]
            
            # 5. æ‹¼æ¥æˆå­—ç¬¦ä¸²
            tag_string = ",".join(processed_tags)
            
            self.logger.debug(f"å¤„ç†æ ‡ç­¾: {raw_tags} â†’ {tag_string}")
            return tag_string
            
        except Exception as e:
            self.logger.error(f"å¤„ç†KOLæ ‡ç­¾å¤±è´¥: {e}")
            return f"{language_tag},Crypto"  # é»˜è®¤è¿”å›è¯­è¨€æ ‡ç­¾+åŠ å¯†è´§å¸æ ‡ç­¾
    
    def _fallback_kol_analysis(self, user_info: Dict[str, Any], 
                              recent_tweets: List[str], language_tag: str) -> Dict[str, Any]:
        """
        å¤‡ç”¨KOLåˆ†æï¼ˆå½“ChatGPTä¸å¯ç”¨æ—¶ï¼‰
        
        Args:
            user_info: ç”¨æˆ·ä¿¡æ¯
            recent_tweets: æœ€è¿‘æ¨æ–‡
            language_tag: è¯­è¨€æ ‡ç­¾
            
        Returns:
            KOLåˆ†æç»“æœ
        """
        try:
            # åŸºäºæ¨æ–‡å†…å®¹è¿›è¡Œç®€å•åˆ†ç±»
            all_text = " ".join(recent_tweets).lower()
            
            # è¯†åˆ«ä¸“ä¸šæ ‡ç­¾
            tag_keywords = {
                "Bitcoin": ["bitcoin", "btc", "æ¯”ç‰¹å¸"],
                "Ethereum": ["ethereum", "eth", "ä»¥å¤ªåŠ", "evm"],
                "DeFi": ["defi", "uniswap", "aave", "compound", "yield", "liquidity"],
                "NFT": ["nft", "opensea", "art", "collection", "mint"],
                "AI": ["ai", "artificial intelligence", "chatgpt", "machine learning"],
                "Gaming": ["gaming", "gamefi", "play to earn", "p2e"],
                "Layer2": ["layer2", "arbitrum", "optimism", "polygon", "scaling"],
                "Meme": ["meme", "doge", "shib", "pepe", "fun"],
                "Trading": ["trading", "chart", "technical analysis", "ta"],
                "RWA": ["rwa", "real world assets", "tokenization"]
            }
            
            detected_tags = [language_tag]  # è¯­è¨€æ ‡ç­¾å¿…é¡»åŒ…å«
            
            for tag_name, keywords in tag_keywords.items():
                if any(keyword in all_text for keyword in keywords):
                    detected_tags.append(tag_name)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä¸“ä¸šæ ‡ç­¾ï¼Œæ·»åŠ é€šç”¨æ ‡ç­¾
            if len(detected_tags) == 1:
                detected_tags.append("Crypto")
            
            # é™åˆ¶æ ‡ç­¾æ•°é‡
            if len(detected_tags) > 5:
                detected_tags = detected_tags[:5]
            
            # ç®€å•çš„æƒ…ç»ªæ£€æµ‹
            sentiment = "neutral"
            if any(word in all_text for word in ["bullish", "moon", "pump", "buy", "ç‰›å¸‚", "çœ‹æ¶¨"]):
                sentiment = "bullish"
            elif any(word in all_text for word in ["bearish", "dump", "crash", "sell", "ç†Šå¸‚", "çœ‹è·Œ"]):
                sentiment = "bearish"
            
            return {
                "type": "influencer",  # é»˜è®¤ç±»å‹
                "tag": ",".join(detected_tags),
                "sentiment": sentiment,
                "summary": f"åŠ å¯†è´§å¸KOLï¼Œä¸»è¦å…³æ³¨{detected_tags[1] if len(detected_tags) > 1 else 'Crypto'}é¢†åŸŸ",
                "trust_rating": 6
            }
            
        except Exception as e:
            self.logger.error(f"å¤‡ç”¨KOLåˆ†æå¤±è´¥: {e}")
            return {
                "type": "influencer",
                "tag": f"{language_tag},Crypto",
                "sentiment": "neutral",
                "summary": "åŠ å¯†è´§å¸ç›¸å…³KOL",
                "trust_rating": 5
            }
    
    def generate_kol_summary(self, user_info: Dict[str, Any], recent_tweets: List[str], 
                            kol_type: str = None) -> Optional[str]:
        """
        ç”ŸæˆKOLæ€»ç»“
        
        Args:
            user_info: ç”¨æˆ·ä¿¡æ¯
            recent_tweets: æœ€è¿‘æ¨æ–‡
            kol_type: KOLç±»å‹
            
        Returns:
            KOLæ€»ç»“æ–‡æœ¬
        """
        try:
            tweets_sample = recent_tweets[:15]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])
            
            prompt = f"""
            è¯·ä¸ºä»¥ä¸‹åŠ å¯†è´§å¸KOLç”Ÿæˆä¸“ä¸šæ€»ç»“ï¼š

            KOLä¿¡æ¯:
            - ç”¨æˆ·å: @{user_info.get('screen_name', 'unknown')}
            - ç±»å‹: {kol_type or 'æœªçŸ¥'}
            - ç²‰ä¸æ•°: {user_info.get('followers_count', 0):,}

            æœ€è¿‘æ¨æ–‡:
            {tweets_text}

            è¯·æä¾›KOLçš„è§‚ç‚¹æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
            1. ä¸»è¦å…³æ³¨çš„é¡¹ç›®å’Œèµ›é“
            2. å¸‚åœºè§‚ç‚¹å’Œé¢„æµ‹å€¾å‘
            3. å½±å“åŠ›å’Œä¸“ä¸šç‰¹ç‚¹
            4. è¿‘æœŸé‡è¦è§‚ç‚¹

            è¦æ±‚ï¼š
            - å®¢è§‚ä¸“ä¸šçš„è¯­è°ƒ
            - 100-200å­—ä»¥å†…
            - çªå‡ºå…¶ç‹¬ç‰¹è§‚ç‚¹å’Œå½±å“åŠ›

            è¯·ç›´æ¥è¿”å›æ€»ç»“æ–‡æœ¬ã€‚
            """
            
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸å¸‚åœºåˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æKOLçš„è§‚ç‚¹å’Œå½±å“åŠ›ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.4,
                max_tokens=250
            )
            
            if response:
                return response.strip()
            
            return None
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆKOLæ€»ç»“å¤±è´¥: {e}")
            return None
    
    def analyze_projects_in_tweets(self, tweets_data: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        ä»æ¨æ–‡ä¸­è¯†åˆ«å’Œåˆ†æåŠ å¯†è´§å¸é¡¹ç›®
        
        Args:
            tweets_data: æ¨æ–‡æ•°æ®åˆ—è¡¨
            
        Returns:
            é¡¹ç›®åˆ†æç»“æœ
        """
        try:
            # é™åˆ¶æ¨æ–‡æ•°é‡
            tweets_sample = tweets_data[:20]
            
            # æ„å»ºæ¨æ–‡å†…å®¹
            tweets_text = []
            for i, tweet in enumerate(tweets_sample, 1):
                content = tweet.get('content', '') or tweet.get('full_text', '')
                user = tweet.get('user_screen_name', '') or tweet.get('screen_name', '')
                engagement = tweet.get('engagement_total', 0)
                
                tweets_text.append(f"{i}. @{user}: {content[:200]}... (äº’åŠ¨æ•°: {engagement})")
            
            tweets_content = "\n".join(tweets_text)
            
            prompt = f"""
            You are a professional cryptocurrency project analysis expert. Please identify, analyze and classify cryptocurrency projects from the following tweets.

            Tweet content:
            {tweets_content}

            Please analyze according to the following rules:

            1. **Project Identification Rules**:
            - Identify complete project names (e.g., "Ethereum", "Uniswap")
            - Identify token symbols (e.g., "ETH", "UNI", "BTC")
            - Identify aliases (e.g., "Ethereum", "Bitcoin", "ETH")
            - Confirm genuine cryptocurrency project discussions

            2. **Project Classification System**:
            - Layer1: Bitcoin, Ethereum, Solana, Cardano
            - Layer2: Arbitrum, Optimism, Polygon, Base  
            - DeFi: Uniswap, AAVE, Compound, MakerDAO
            - GameFi: Axie Infinity, The Sandbox
            - NFT: OpenSea, Blur, LooksRare
            - Infrastructure: Chainlink, The Graph
            - Meme: Dogecoin, Shiba Inu, PEPE
            - AI: Fetch.ai, SingularityNET
            - Privacy: Monero, Zcash

            3. **Narrative Tag System**:
            - Technical narratives: "Scalability", "Interoperability", "Privacy"
            - Application narratives: "DeFi Summer", "NFT Boom", "GameFi", "RWA"
            - Ecosystem narratives: "Ethereum Killers", "Multi-chain"
            - Emerging narratives: "AI+Crypto", "DePin", "Liquid Staking"

            4. **Sentiment Analysis Framework**:
            - Positive sentiment (70-100 points): bullish, recommendation, technical breakthrough
            - Neutral sentiment (30-70 points): objective analysis, technical discussion
            - Negative sentiment (0-30 points): bearish, risk warning

            Please return analysis results in JSON format:
            {{
                "projects": [
                    {{
                        "project_id": "ethereum_eth",
                        "name": "Ethereum", 
                        "symbol": "ETH",
                        "category": "Layer1",
                        "narratives": ["Smart Contract Platform", "DeFi"],
                        "sentiment_index": 75.5,
                        "popularity_score": 850,
                        "summary": "Ethereum discussions mainly focus on technical upgrades...",
                        "confidence_score": 0.95,
                        "total_mentions": 5
                    }}
                ],
                "analysis_summary": {{
                    "total_projects_identified": 3,
                    "dominant_narratives": ["DeFi", "Layer2"],
                    "overall_market_sentiment": "bullish"
                }}
            }}
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency project analysis expert skilled in identifying projects from tweets and conducting in-depth analysis."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.3,
                max_tokens=2000
            )
            
            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()
                    
                    # å°è¯•è§£æJSONå“åº”
                    result = json.loads(cleaned_response)
                    
                    # éªŒè¯è¿”å›çš„æ•°æ®
                    if isinstance(result, dict) and 'projects' in result:
                        return result
                        
                except json.JSONDecodeError:
                    self.logger.warning(f"ChatGPTé¡¹ç›®åˆ†æè¿”å›æ ¼å¼é”™è¯¯: {response[:200]}...")
                    return None
            
            return None
            
        except Exception as e:
            self.logger.error(f"é¡¹ç›®åˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_project_summary(self, project_info: Dict[str, Any], 
                                related_tweets: List[str]) -> Optional[str]:
        """
        ç”Ÿæˆé¡¹ç›®æ€»ç»“
        
        Args:
            project_info: é¡¹ç›®åŸºæœ¬ä¿¡æ¯
            related_tweets: ç›¸å…³æ¨æ–‡åˆ—è¡¨
            
        Returns:
            é¡¹ç›®æ€»ç»“æ–‡æœ¬
        """
        try:
            tweets_sample = related_tweets[:10]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])
            
            prompt = f"""
            Please generate a professional summary for the cryptocurrency project:

            Project Information:
            - Name: {project_info.get('name', 'Unknown')}
            - Symbol: {project_info.get('symbol', 'Unknown')}
            - Category: {project_info.get('category', 'Unknown')}
            - Narratives: {', '.join(project_info.get('narratives', []))}

            Related Tweet Discussions:
            {tweets_text}

            Please provide a community discussion summary for the project, including:
            1. Main discussion focus and trending topics
            2. Community sentiment and market expectations
            3. KOL opinions and professional analysis
            4. Project development updates and technical progress
            5. Risk factors and concerns

            Requirements:
            - Objective and professional tone
            - 120-150 words
            - Highlight the project's unique value and market position
            - Reflect latest community discussion trends

            Please return the summary text directly.
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency project analyst skilled in analyzing project community sentiment and market performance."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.4,
                max_tokens=350
            )
            
            if response:
                return response.strip()
            
            return None
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆé¡¹ç›®æ€»ç»“å¤±è´¥: {e}")
            return None
    
    def calculate_project_sentiment(self, project_tweets: List[str]) -> Optional[float]:
        """
        è®¡ç®—é¡¹ç›®æƒ…æ„ŸæŒ‡æ•°
        
        Args:
            project_tweets: é¡¹ç›®ç›¸å…³æ¨æ–‡åˆ—è¡¨
            
        Returns:
            æƒ…æ„ŸæŒ‡æ•° (0-100)
        """
        try:
            if not project_tweets:
                return None
            
            tweets_sample = project_tweets[:15]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])
            
            prompt = f"""
            Please analyze the overall sentiment tendency of the following tweets toward the cryptocurrency project:

            Tweet Content:
            {tweets_text}

            Analysis Framework:
            - Positive sentiment (70-100 points): bullish predictions, technical breakthroughs, partnership news, institutional adoption
            - Neutral sentiment (30-70 points): objective analysis, technical discussion, neutral reporting
            - Negative sentiment (0-30 points): bearish predictions, risk warnings, technical issues, negative news

            Please consider comprehensively:
            1. Emotional tone and language of tweets
            2. Price predictions and market expectations
            3. Technical development and project progress
            4. Risk factors and concerns
            5. Community activity and engagement

            Please return a sentiment index score from 0-100 with a brief explanation of the rating.

            Format:
            {{
                "sentiment_index": 75.5,
                "reasoning": "Overall sentiment is positive, mainly based on technical progress and market expectations..."
            }}
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency sentiment analysis expert skilled in quantifying community sentiment."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.2,
                max_tokens=200
            )

            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()

                    result = json.loads(cleaned_response)
                    return result.get('sentiment_index')
                except json.JSONDecodeError:
                    # å°è¯•æå–æ•°å­—
                    import re
                    match = re.search(r'(\d+\.?\d*)', response)
                    if match:
                        return float(match.group(1))

            return None

        except Exception as e:
            self.logger.error(f"è®¡ç®—é¡¹ç›®æƒ…æ„Ÿå¤±è´¥: {e}")
            return None
    
    def analyze_projects_in_tweets(self, tweets_data: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        ä»æ¨æ–‡ä¸­è¯†åˆ«å’Œåˆ†æåŠ å¯†è´§å¸é¡¹ç›®
        
        Args:
            tweets_data: æ¨æ–‡æ•°æ®åˆ—è¡¨
            
        Returns:
            é¡¹ç›®åˆ†æç»“æœ
        """
        try:
            # é™åˆ¶æ¨æ–‡æ•°é‡
            tweets_sample = tweets_data[:20]
            
            # æ„å»ºæ¨æ–‡å†…å®¹
            tweets_text = []
            for i, tweet in enumerate(tweets_sample, 1):
                content = tweet.get('content', '') or tweet.get('full_text', '')
                user = tweet.get('user_screen_name', '') or tweet.get('screen_name', '')
                engagement = tweet.get('engagement_total', 0)
                
                tweets_text.append(f"{i}. @{user}: {content[:200]}... (äº’åŠ¨æ•°: {engagement})")
            
            tweets_content = "\n".join(tweets_text)
            
            prompt = f"""
            You are a professional cryptocurrency project analysis expert. Please identify, analyze and classify cryptocurrency projects from the following tweets.

            Tweet content:
            {tweets_content}

            Please analyze according to the following rules:

            1. **Project Identification Rules**:
            - Identify complete project names (e.g., "Ethereum", "Uniswap")
            - Identify token symbols (e.g., "ETH", "UNI", "BTC")
            - Identify aliases (e.g., "Ethereum", "Bitcoin", "ETH")
            - Confirm genuine cryptocurrency project discussions

            2. **Project Classification System**:
            - Layer1: Bitcoin, Ethereum, Solana, Cardano
            - Layer2: Arbitrum, Optimism, Polygon, Base  
            - DeFi: Uniswap, AAVE, Compound, MakerDAO
            - GameFi: Axie Infinity, The Sandbox
            - NFT: OpenSea, Blur, LooksRare
            - Infrastructure: Chainlink, The Graph
            - Meme: Dogecoin, Shiba Inu, PEPE
            - AI: Fetch.ai, SingularityNET
            - Privacy: Monero, Zcash

            3. **Narrative Tag System**:
            - Technical narratives: "Scalability", "Interoperability", "Privacy"
            - Application narratives: "DeFi Summer", "NFT Boom", "GameFi", "RWA"
            - Ecosystem narratives: "Ethereum Killers", "Multi-chain"
            - Emerging narratives: "AI+Crypto", "DePin", "Liquid Staking"

            4. **Sentiment Analysis Framework**:
            - Positive sentiment (70-100 points): bullish, recommendation, technical breakthrough
            - Neutral sentiment (30-70 points): objective analysis, technical discussion
            - Negative sentiment (0-30 points): bearish, risk warning

            Please return analysis results in JSON format:
            {{
                "projects": [
                    {{
                        "project_id": "ethereum_eth",
                        "name": "Ethereum", 
                        "symbol": "ETH",
                        "category": "Layer1",
                        "narratives": ["Smart Contract Platform", "DeFi"],
                        "sentiment_index": 75.5,
                        "popularity_score": 850,
                        "summary": "Ethereum discussions mainly focus on technical upgrades...",
                        "confidence_score": 0.95,
                        "total_mentions": 5
                    }}
                ],
                "analysis_summary": {{
                    "total_projects_identified": 3,
                    "dominant_narratives": ["DeFi", "Layer2"],
                    "overall_market_sentiment": "bullish"
                }}
            }}
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency project analysis expert skilled in identifying projects from tweets and conducting in-depth analysis."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.3,
                max_tokens=2000
            )
            
            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()
                    
                    # å°è¯•è§£æJSONå“åº”
                    result = json.loads(cleaned_response)
                    
                    # éªŒè¯è¿”å›çš„æ•°æ®
                    if isinstance(result, dict) and 'projects' in result:
                        return result
                        
                except json.JSONDecodeError:
                    self.logger.warning(f"ChatGPTé¡¹ç›®åˆ†æè¿”å›æ ¼å¼é”™è¯¯: {response[:200]}...")
                    return None
            
            return None
            
        except Exception as e:
            self.logger.error(f"é¡¹ç›®åˆ†æå¤±è´¥: {e}")
            return None
    
    def generate_project_summary(self, project_info: Dict[str, Any], 
                                related_tweets: List[str]) -> Optional[str]:
        """
        ç”Ÿæˆé¡¹ç›®æ€»ç»“
        
        Args:
            project_info: é¡¹ç›®åŸºæœ¬ä¿¡æ¯
            related_tweets: ç›¸å…³æ¨æ–‡åˆ—è¡¨
            
        Returns:
            é¡¹ç›®æ€»ç»“æ–‡æœ¬
        """
        try:
            tweets_sample = related_tweets[:10]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])
            
            prompt = f"""
            Please generate a professional summary for the cryptocurrency project:

            Project Information:
            - Name: {project_info.get('name', 'Unknown')}
            - Symbol: {project_info.get('symbol', 'Unknown')}
            - Category: {project_info.get('category', 'Unknown')}
            - Narratives: {', '.join(project_info.get('narratives', []))}

            Related Tweet Discussions:
            {tweets_text}

            Please provide a community discussion summary for the project, including:
            1. Main discussion focus and trending topics
            2. Community sentiment and market expectations
            3. KOL opinions and professional analysis
            4. Project development updates and technical progress
            5. Risk factors and concerns

            Requirements:
            - Objective and professional tone
            - 120-150 words
            - Highlight the project's unique value and market position
            - Reflect latest community discussion trends

            Please return the summary text directly.
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency project analyst skilled in analyzing project community sentiment and market performance."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.4,
                max_tokens=350
            )
            
            if response:
                return response.strip()
            
            return None
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆé¡¹ç›®æ€»ç»“å¤±è´¥: {e}")
            return None
    
    def calculate_project_sentiment(self, project_tweets: List[str]) -> Optional[float]:
        """
        è®¡ç®—é¡¹ç›®æƒ…æ„ŸæŒ‡æ•°
        
        Args:
            project_tweets: é¡¹ç›®ç›¸å…³æ¨æ–‡åˆ—è¡¨
            
        Returns:
            æƒ…æ„ŸæŒ‡æ•° (0-100)
        """
        try:
            if not project_tweets:
                return None
            
            tweets_sample = project_tweets[:15]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])
            
            prompt = f"""
            Please analyze the overall sentiment tendency of the following tweets toward the cryptocurrency project:

            Tweet Content:
            {tweets_text}

            Analysis Framework:
            - Positive sentiment (70-100 points): bullish predictions, technical breakthroughs, partnership news, institutional adoption
            - Neutral sentiment (30-70 points): objective analysis, technical discussion, neutral reporting
            - Negative sentiment (0-30 points): bearish predictions, risk warnings, technical issues, negative news

            Please consider comprehensively:
            1. Emotional tone and language of tweets
            2. Price predictions and market expectations
            3. Technical development and project progress
            4. Risk factors and concerns
            5. Community activity and engagement

            Please return a sentiment index score from 0-100 with a brief explanation of the rating.

            Format:
            {{
                "sentiment_index": 75.5,
                "reasoning": "Overall sentiment is positive, mainly based on technical progress and market expectations..."
            }}
            """
            
            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency sentiment analysis expert skilled in quantifying community sentiment."},
                {"role": "user", "content": prompt}
            ]
            
            response = self._make_request(
                messages=messages,
                temperature=0.2,
                max_tokens=200
            )

            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()

                    result = json.loads(cleaned_response)
                    return result.get('sentiment_index')
                except json.JSONDecodeError:
                    # å°è¯•æå–æ•°å­—
                    import re
                    match = re.search(r'(\d+\.?\d*)', response)
                    if match:
                        return float(match.group(1))

            return None

        except Exception as e:
            self.logger.error(f"è®¡ç®—é¡¹ç›®æƒ…æ„Ÿå¤±è´¥: {e}")
            return None
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0

    def extract_token_symbols_from_tweet(self, tweet_content: str) -> Optional[List[str]]:
        """
        ä»æ¨æ–‡ä¸­æå–åŠ å¯†è´§å¸token symbols

        Args:
            tweet_content: æ¨æ–‡å†…å®¹

        Returns:
            æå–çš„token symbolåˆ—è¡¨ï¼ˆå¦‚["BTC", "ETH"]ï¼‰ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            prompt = f"""
            Please analyze the following cryptocurrency-related tweet and extract all mentioned token symbols.

            Tweet content: {tweet_content}

            Please identify:
            1. All cryptocurrency token symbols mentioned (e.g., BTC, ETH, SOL, USDT)
            2. Include symbols with $ prefix (e.g., $BTC, $ETH)
            3. Include full names that can be mapped to symbols (e.g., "Bitcoin" -> BTC, "Ethereum" -> ETH)

            Requirements:
            - Only extract valid cryptocurrency token symbols (2-10 uppercase letters)
            - Exclude common words that look like symbols but are not (e.g., "TO", "FOR", "AND")
            - Return empty list if no valid symbols found
            - Return at most 10 symbols

            Please return in JSON format:
            {{"symbols": ["BTC", "ETH", "SOL"]}}

            If no valid symbols found, return:
            {{"symbols": []}}
            """

            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency analyst skilled in identifying token symbols from social media content."},
                {"role": "user", "content": prompt}
            ]

            response = self._make_request(
                messages=messages,
                temperature=0.1,  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ç»“æœ
                max_tokens=150
            )

            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()

                    # å°è¯•è§£æJSONå“åº”
                    result = json.loads(cleaned_response)

                    # éªŒè¯è¿”å›çš„æ•°æ®
                    if isinstance(result, dict) and 'symbols' in result:
                        symbols = result['symbols']

                        if isinstance(symbols, list):
                            # è¿‡æ»¤å’Œæ ‡å‡†åŒ–symbols
                            filtered_symbols = []
                            for symbol in symbols:
                                if isinstance(symbol, str):
                                    # ç§»é™¤$å‰ç¼€å¹¶è½¬ä¸ºå¤§å†™
                                    clean_symbol = symbol.strip().upper().lstrip('$')
                                    # éªŒè¯é•¿åº¦
                                    if 2 <= len(clean_symbol) <= 10:
                                        filtered_symbols.append(clean_symbol)

                            # å»é‡å¹¶é™åˆ¶æ•°é‡
                            unique_symbols = list(set(filtered_symbols))[:10]

                            if unique_symbols:
                                self.logger.debug(f"æå–åˆ°token symbols: {unique_symbols}")
                                return unique_symbols
                            else:
                                return None

                except json.JSONDecodeError:
                    self.logger.warning(f"ChatGPTè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {response}")
                    return None

            return None

        except Exception as e:
            self.logger.error(f"æå–token symbolså¤±è´¥: {e}")
            return None

    def classify_tweet_announcement(self, tweet_content: str) -> int:
        """
        åˆ¤æ–­æ¨æ–‡æ˜¯å¦ä¸ºé‡è¦å…¬å‘Šï¼ˆåˆä½œä¼™ä¼´ã€ç¤¾åŒºæ´»åŠ¨ã€æŠ€æœ¯æ›´æ–°ï¼‰

        Args:
            tweet_content: æ¨æ–‡å†…å®¹

        Returns:
            1è¡¨ç¤ºæ˜¯é‡è¦å…¬å‘Šï¼Œ0è¡¨ç¤ºä¸æ˜¯
        """
        try:
            prompt = f"""
You are given the content of a tweet from the official account of a crypto project.
Your task is to determine whether the tweet falls into one or more of the following categories:

* **key ecosystem partners & collaborations**: announcements about strategic partners, ecosystem alliances, collaborations with other projects or companies.
* **Community space and other events**: announcements about AMA sessions, Twitter Spaces, conferences, hackathons, offline/online meetups, or community-related activities.
* **Major Tech Updates**: announcements about new product releases, protocol upgrades, mainnet/testnet launches, technical milestones, or major software updates.

Tweet content: {tweet_content}

Please analyze the tweet and determine if it matches ANY of the above categories.

Return in JSON format:
{{"is_announcement": true or false, "categories": ["category1", "category2"], "reason": "brief explanation"}}

If the tweet does NOT match any category, return:
{{"is_announcement": false, "categories": [], "reason": "brief explanation"}}
"""

            messages = [
                {"role": "system", "content": "You are a professional crypto content analyst skilled in identifying important announcements from project tweets."},
                {"role": "user", "content": prompt}
            ]

            response = self._make_request(
                messages=messages,
                temperature=0.1,  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ç»“æœ
                max_tokens=200
            )

            if response:
                try:
                    # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤ä»£ç å—æ ‡è®°
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```json'):
                        cleaned_response = cleaned_response[7:]  # ç§»é™¤ ```json
                    if cleaned_response.startswith('```'):
                        cleaned_response = cleaned_response[3:]  # ç§»é™¤ ```
                    if cleaned_response.endswith('```'):
                        cleaned_response = cleaned_response[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                    cleaned_response = cleaned_response.strip()

                    # å°è¯•è§£æJSONå“åº”
                    result = json.loads(cleaned_response)

                    # éªŒè¯è¿”å›çš„æ•°æ®
                    if isinstance(result, dict) and 'is_announcement' in result:
                        is_announcement = result['is_announcement']
                        categories = result.get('categories', [])
                        reason = result.get('reason', '')

                        if is_announcement:
                            self.logger.info(f"è¯†åˆ«ä¸ºé‡è¦å…¬å‘Š: ç±»åˆ«={categories}, ç†ç”±={reason}")
                            return 1
                        else:
                            self.logger.debug(f"éé‡è¦å…¬å‘Š: {reason}")
                            return 0

                except json.JSONDecodeError:
                    self.logger.warning(f"ChatGPTè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSON: {response}")
                    return 0

            return 0

        except Exception as e:
            self.logger.error(f"åˆ¤æ–­å…¬å‘Šç±»å‹å¤±è´¥: {e}")
            return 0

    def summarize_announcement(self, tweet_content: str) -> Optional[str]:
        """
        Generate a concise announcement summary from a tweet (max 50 characters in Chinese or 50 words in English)

        Args:
            tweet_content: Original tweet content

        Returns:
            Concise announcement-style summary, or None if failed
        """
        try:
            prompt = f"""
You are a professional crypto project announcement editor. Your task is to transform the following tweet into a concise, professional announcement summary.

Original tweet: {tweet_content}

Requirements:
1. Rewrite the tweet to sound like an official announcement rather than a casual social media post
2. Keep it concise: maximum 50 characters in Chinese OR 50 words in English
3. Focus on the key announcement content (what is happening, when, who is involved)
4. Use professional and formal tone
5. Remove casual language, emojis, and unnecessary details
6. Preserve important information like dates, partner names, event names, or technical updates

Return ONLY the summary text without any additional explanation or formatting.

Example:
Input: "ğŸ‰ Excited to announce our partnership with @ABC! This is huge for our ecosystem! Stay tuned for more details ğŸš€"
Output: "Partnership announced with ABC to expand ecosystem capabilities"

Now generate the summary:
"""

            messages = [
                {"role": "system", "content": "You are a professional crypto announcement editor skilled in creating concise, formal summaries from social media posts."},
                {"role": "user", "content": prompt}
            ]

            response = self._make_request(
                messages=messages,
                temperature=0.3,  # Moderate temperature for professional yet concise output
                max_tokens=100    # Limit tokens to ensure conciseness
            )

            if response:
                summary = response.strip()

                # Validate length (rough check)
                if len(summary) > 0:
                    self.logger.info(f"Generated announcement summary: {summary[:100]}...")
                    return summary
                else:
                    self.logger.warning("Generated summary is empty")
                    return None

            return None

        except Exception as e:
            self.logger.error(f"Failed to generate announcement summary: {e}")
            return None

    def detect_campaign_announcement(self, tweets_content: List[str]) -> bool:
        """
        æ£€æµ‹æ¨æ–‡æ˜¯å¦åŒ…å«æ´»åŠ¨å…¬å‘Šå…³é”®è¯

        å…³é”®è¯åŒ…æ‹¬: campaign, airdrop, quest, reward, giveaway

        Args:
            tweets_content: æ¨æ–‡å†…å®¹åˆ—è¡¨

        Returns:
            æ˜¯å¦ä¸ºæ´»åŠ¨å…¬å‘Š
        """
        try:
            # åˆå¹¶æ¨æ–‡å†…å®¹
            combined_content = "\n".join(tweets_content[:10])  # é™åˆ¶æ¨æ–‡æ•°é‡

            prompt = f"""
            Analyze the following tweets and determine if they contain campaign/event announcements.

            Key indicators of campaign announcements include:
            - campaign
            - airdrop
            - quest
            - reward
            - giveaway

            Also look for related terms like:
            - token distribution
            - community rewards
            - participation incentives
            - bounty program
            - contest
            - prize

            Tweets content:
            {combined_content}

            Task: Determine if these tweets announce or discuss a campaign, airdrop, quest, reward program, or giveaway.

            Return ONLY "true" if it's a campaign announcement, or "false" if it's not.
            Return a single word without any additional explanation.
            """

            messages = [
                {"role": "system", "content": "You are a cryptocurrency campaign and airdrop detection expert. Analyze tweets to identify campaign announcements accurately."},
                {"role": "user", "content": prompt}
            ]

            response = self._make_request(
                messages=messages,
                temperature=0.1,  # Low temperature for consistent detection
                max_tokens=10
            )

            if response:
                result = response.strip().lower()
                is_campaign = result == "true" or "true" in result

                self.logger.info(f"Campaign detection result: {is_campaign}")
                return is_campaign

            return False

        except Exception as e:
            self.logger.error(f"Failed to detect campaign announcement: {e}")
            return False

    def generate_campaign_summary(self, project_info: Dict[str, Any],
                                 tweets_content: List[str]) -> Optional[str]:
        """
        ç”Ÿæˆæ´»åŠ¨å…¬å‘Šæ‘˜è¦ï¼ˆè‹±æ–‡æç¤ºè¯ï¼‰

        Args:
            project_info: é¡¹ç›®åŸºæœ¬ä¿¡æ¯
            tweets_content: ç›¸å…³æ¨æ–‡å†…å®¹åˆ—è¡¨

        Returns:
            æ´»åŠ¨æ‘˜è¦æ–‡æœ¬
        """
        try:
            # åˆå¹¶æ¨æ–‡å†…å®¹
            tweets_sample = tweets_content[:10]
            tweets_text = "\n".join([f"- {tweet}" for tweet in tweets_sample])

            prompt = f"""
            Generate a professional campaign announcement summary for the cryptocurrency project.

            Project Information:
            - Name: {project_info.get('name', 'Unknown')}
            - Symbol: {project_info.get('symbol', 'Unknown')}
            - Category: {project_info.get('category', 'Unknown')}

            Related Campaign Tweets:
            {tweets_text}

            Please provide a comprehensive campaign summary including:
            1. Campaign Type: Specify if it's an airdrop, quest, reward program, giveaway, or other campaign type
            2. Key Details: What participants need to do, eligibility criteria, rewards offered
            3. Timeline: Start date, end date, or duration if mentioned
            4. Requirements: Specific actions required (follow, retweet, hold tokens, complete tasks, etc.)
            5. Reward Distribution: How and when rewards will be distributed

            Requirements:
            - Professional and clear tone
            - 100-150 words
            - Focus on actionable information for potential participants
            - Highlight important dates and requirements
            - Use English for the summary

            Return ONLY the summary text without any additional formatting or labels.
            """

            messages = [
                {"role": "system", "content": "You are a professional cryptocurrency campaign analyst skilled in summarizing campaign announcements clearly and concisely."},
                {"role": "user", "content": prompt}
            ]

            response = self._make_request(
                messages=messages,
                temperature=0.3,
                max_tokens=300
            )

            if response:
                summary = response.strip()

                if len(summary) > 0:
                    self.logger.info(f"Generated campaign summary: {summary[:100]}...")
                    return summary
                else:
                    self.logger.warning("Generated campaign summary is empty")
                    return None

            return None

        except Exception as e:
            self.logger.error(f"Failed to generate campaign summary: {e}")
            return None

    def extract_activity_structured_data(self, tweet_text: str, tweet_url: str,
                                         tweet_time: str) -> Optional[Dict[str, str]]:
        """
        ä»æ¨æ–‡ä¸­æå–ç»“æ„åŒ–çš„æ´»åŠ¨æ•°æ®ï¼ˆæ–°JSONæ ¼å¼ï¼‰

        Args:
            tweet_text: æ¨æ–‡å†…å®¹ï¼ˆfull_textï¼‰
            tweet_url: æ¨æ–‡é“¾æ¥
            tweet_time: æ¨æ–‡æ—¶é—´

        Returns:
            ç»“æ„åŒ–çš„æ´»åŠ¨æ•°æ®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - title: æ´»åŠ¨æ ‡é¢˜ï¼ˆ5ä¸ªè¯ä»¥å†…ï¼‰
            - status: æ´»åŠ¨çŠ¶æ€ï¼ˆé»˜è®¤"Active"ï¼‰
            - summary: æ´»åŠ¨æ‘˜è¦ï¼ˆ20ä¸ªè¯ä»¥å†…ï¼‰
            - time: æ¨æ–‡æ—¶é—´
            - url: æ¨æ–‡é“¾æ¥
        """
        try:
            prompt = f"""
            Extract and structure campaign/activity information from this tweet into JSON format.

            Tweet Content:
            {tweet_text}

            Task: Extract the following information and return ONLY a valid JSON object:
            {{
                "title": "Activity title in 5 words or less",
                "status": "Active",
                "summary": "Activity summary in 20 words or less",
                "time": "{tweet_time}",
                "url": "{tweet_url}"
            }}

            Requirements:
            1. title: Create a concise title (max 5 words) that captures the campaign type and project
            2. status: Always set to "Active" for current activities
            3. summary: Provide a brief summary (max 20 words) covering key participation details
            4. time: Use the provided tweet time as-is
            5. url: Use the provided tweet URL as-is

            Important:
            - Return ONLY the JSON object, no additional text
            - All text should be in English
            - Keep title and summary concise and clear
            - Focus on actionable information (what, how, rewards)

            Return the JSON object:
            """

            messages = [
                {"role": "system", "content": "You are a data extraction specialist. Extract campaign information and return valid JSON only."},
                {"role": "user", "content": prompt}
            ]

            response = self._make_request(
                messages=messages,
                temperature=0.1,  # Low temperature for consistent extraction
                max_tokens=200
            )

            if response:
                # Parse JSON response
                import json
                try:
                    # Clean response (remove markdown code blocks if present)
                    cleaned_response = response.strip()
                    if cleaned_response.startswith('```'):
                        # Remove markdown code blocks
                        lines = cleaned_response.split('\n')
                        cleaned_response = '\n'.join([l for l in lines if not l.startswith('```')])

                    activity_data = json.loads(cleaned_response.strip())

                    # Validate required fields
                    required_fields = ['title', 'status', 'summary', 'time', 'url']
                    if all(field in activity_data for field in required_fields):
                        self.logger.info(f"Extracted activity data: {activity_data['title']}")
                        return activity_data
                    else:
                        self.logger.warning(f"Missing required fields in activity data: {activity_data}")
                        return None

                except json.JSONDecodeError as e:
                    self.logger.error(f"Failed to parse JSON response: {e}")
                    self.logger.error(f"Response was: {response}")
                    return None

            return None

        except Exception as e:
            self.logger.error(f"Failed to extract activity structured data: {e}")
            return None


# å…¨å±€ChatGPTå®¢æˆ·ç«¯å®ä¾‹
chatgpt_client = ChatGPTClient() 