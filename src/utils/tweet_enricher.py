"""
æ¨æ–‡å¢å¼ºå¤„ç†å™¨
å¤„ç†æ¨æ–‡çš„kol_idå’Œentity_idå­—æ®µï¼Œä»¥åŠè¯é¢˜åˆ†æå’Œå­˜å‚¨
"""
import logging
import uuid
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

from ..api.chatgpt_client import chatgpt_client
from ..database.topic_dao import topic_dao
from ..database.kol_dao import kol_dao
from ..database.project_dao import ProjectDAO
from ..models.tweet import Tweet
from ..models.topic import Topic
from ..models.project import Project
from .advanced_topic_processor import advanced_topic_processor
from .smart_classifier import smart_classifier


class TweetEnricher:
    """æ¨æ–‡å¢å¼ºå¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨æ–‡å¢å¼ºå™¨"""
        self.logger = logging.getLogger(__name__)
        self.chatgpt = chatgpt_client
        self.topic_dao = topic_dao
        self.kol_dao = kol_dao
        self.project_dao = ProjectDAO()
        
        # ç¼“å­˜å·²çŸ¥çš„KOLç”¨æˆ·IDï¼Œé¿å…é‡å¤æŸ¥è¯¢
        self._kol_user_cache = {}
        self._refresh_kol_cache()
    
    def _refresh_kol_cache(self):
        """åˆ·æ–°KOLç”¨æˆ·ç¼“å­˜"""
        try:
            kols = self.kol_dao.get_active_kols()
            self._kol_user_cache = {kol.user_id: kol.kol_id for kol in kols}
            self.logger.info(f"åˆ·æ–°KOLç¼“å­˜ï¼Œæ‰¾åˆ° {len(self._kol_user_cache)} ä¸ªKOLç”¨æˆ·")
        except Exception as e:
            self.logger.error(f"åˆ·æ–°KOLç¼“å­˜å¤±è´¥: {e}")
            self._kol_user_cache = {}
    
    def enrich_tweets(self, tweets: List[Tweet], 
                     user_data_map: Dict[str, Dict[str, Any]]) -> List[Tweet]:
        """
        æ‰¹é‡å¢å¼ºæ¨æ–‡æ•°æ®
        
        Args:
            tweets: æ¨æ–‡åˆ—è¡¨
            user_data_map: ç”¨æˆ·æ•°æ®æ˜ å°„ {user_id: user_data}
            
        Returns:
            å¢å¼ºåçš„æ¨æ–‡åˆ—è¡¨
        """
        try:
            enriched_tweets = []
            
            for tweet in tweets:
                try:
                    # å¢å¼ºå•æ¡æ¨æ–‡
                    enriched_tweet = self.enrich_single_tweet(tweet, user_data_map)
                    if enriched_tweet:
                        enriched_tweets.append(enriched_tweet)
                    else:
                        # å¦‚æœå¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¨æ–‡
                        enriched_tweets.append(tweet)
                        
                except Exception as e:
                    self.logger.error(f"å¢å¼ºæ¨æ–‡ {tweet.id_str} å¤±è´¥: {e}")
                    enriched_tweets.append(tweet)
            
            self.logger.info(f"æ¨æ–‡å¢å¼ºå®Œæˆï¼Œå¤„ç† {len(enriched_tweets)} æ¡æ¨æ–‡")
            return enriched_tweets
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡å¢å¼ºæ¨æ–‡å¤±è´¥: {e}")
            return tweets
    
    def enrich_single_tweet(self, tweet: Tweet, 
                          user_data_map: Dict[str, Dict[str, Any]]) -> Optional[Tweet]:
        """
        å¢å¼ºå•æ¡æ¨æ–‡
        
        Args:
            tweet: æ¨æ–‡å¯¹è±¡
            user_data_map: ç”¨æˆ·æ•°æ®æ˜ å°„
            
        Returns:
            å¢å¼ºåçš„æ¨æ–‡å¯¹è±¡
        """
        try:
            # 1. è®¾ç½® kol_idï¼ˆä»ç”¨æˆ·æ•°æ®ä¸­è·å– user.id_strï¼‰
            kol_id = self._extract_kol_id_from_user_data(tweet, user_data_map)
            tweet.kol_id = kol_id
            
            # 2. ç”Ÿæˆæ¨æ–‡URL
            tweet_url = self._generate_tweet_url(tweet)
            tweet.tweet_url = tweet_url
            
            # 3. å†…å®¹è´¨é‡æ£€æŸ¥ï¼šåˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Cryptoç›¸å…³å†…å®¹
            is_valid = self._validate_crypto_content(tweet.full_text, use_ai=True)
            tweet.is_valid = is_valid
            
            # 4. ä»…å¯¹æœ‰æ•ˆæ¨æ–‡è¿›è¡Œè¿›ä¸€æ­¥åˆ†æ
            if is_valid:
                # 4.1 æƒ…ç»ªåˆ†æ
                sentiment = self._analyze_tweet_sentiment(tweet.full_text, use_ai=True)
                tweet.sentiment = sentiment
                
                # 4.2 ä½¿ç”¨æ™ºèƒ½åˆ†ç±»å™¨å¤„ç†é¡¹ç›®å’Œè¯é¢˜
                classification_result = self._classify_and_set_ids(tweet)
                
                # è®¾ç½®ç›¸åº”çš„IDå­—æ®µï¼ˆç¡®ä¿äº’æ–¥æ€§ï¼‰
                if classification_result.content_type == 'project':
                    tweet.project_id = classification_result.project_id
                    tweet.topic_id = None  # ç¡®ä¿topic_idä¸ºç©º
                    tweet.entity_id = classification_result.project_id
                elif classification_result.content_type == 'topic':
                    tweet.project_id = None  # ç¡®ä¿project_idä¸ºç©º
                    tweet.topic_id = classification_result.topic_id
                    tweet.entity_id = classification_result.topic_id
                else:
                    # æœªçŸ¥ç±»å‹ï¼Œæ¸…ç©ºæ‰€æœ‰åˆ†ç±»å­—æ®µ
                    tweet.project_id = None
                    tweet.topic_id = None
                    tweet.entity_id = None
                
                self.logger.info(f"æ¨æ–‡ {tweet.id_str} å¢å¼ºå®Œæˆ: kol_id={kol_id}, valid={is_valid}, sentiment={sentiment}, project_id={tweet.project_id}, topic_id={tweet.topic_id}, entity_id={tweet.entity_id}, url={tweet_url}")
            else:
                # æ— æ•ˆæ¨æ–‡ä¸è¿›è¡Œè¯é¢˜åˆ†æå’Œæƒ…ç»ªåˆ†æ
                tweet.sentiment = None
                tweet.entity_id = None
                tweet.project_id = None
                tweet.topic_id = None
                self.logger.info(f"æ¨æ–‡ {tweet.id_str} æ ‡è®°ä¸ºæ— æ•ˆï¼Œkol_id={kol_id}, url={tweet_url}")
            
            return tweet
            
        except Exception as e:
            self.logger.error(f"å¢å¼ºæ¨æ–‡ {tweet.id_str} å¤±è´¥: {e}")
            return None
    
    def _validate_crypto_content(self, text: str, use_ai: bool = True) -> bool:
        """
        éªŒè¯æ¨æ–‡æ˜¯å¦ä¸ºæœ‰æ•ˆçš„åŠ å¯†è´§å¸ç›¸å…³å†…å®¹ï¼ˆä¸”éå¹¿å‘Šï¼‰
        
        Args:
            text: æ¨æ–‡å†…å®¹
            use_ai: æ˜¯å¦ä½¿ç”¨AIåˆ†æï¼ˆé»˜è®¤ä½¿ç”¨å…³é”®è¯æ¨¡å¼é¿å…APIæ¶ˆè€—ï¼‰
            
        Returns:
            æ˜¯å¦ä¸ºæœ‰æ•ˆå†…å®¹
        """
        try:
            if not text or len(text.strip()) < 10:
                return False
            
            text_lower = text.lower()
            
            # æ–¹æ³•1: ä½¿ç”¨AIåˆ†æï¼ˆå¦‚æœAPIå¯ç”¨ä¸”å¯ç”¨ï¼‰
            if use_ai:
                validation_result = self._ai_validate_content(text)
                if validation_result is not None:
                    return validation_result
            
            # æ–¹æ³•2: åŸºäºå…³é”®è¯çš„å†…å®¹éªŒè¯ï¼ˆé»˜è®¤æ–¹æ³•ï¼‰
            return self._keyword_validate_content(text_lower)
            
        except Exception as e:
            self.logger.error(f"å†…å®¹éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _keyword_validate_content(self, text_lower: str) -> bool:
        """
        åŸºäºå…³é”®è¯çš„å†…å®¹éªŒè¯
        
        Args:
            text_lower: å°å†™æ–‡æœ¬å†…å®¹
            
        Returns:
            æ˜¯å¦ä¸ºæœ‰æ•ˆå†…å®¹
        """
        try:
            # åŠ å¯†è´§å¸ç›¸å…³å…³é”®è¯
            crypto_keywords = [
                'bitcoin', 'btc', 'ethereum', 'eth', 'crypto', 'cryptocurrency',
                'blockchain', 'defi', 'nft', 'dao', 'web3', 'altcoin',
                'doge', 'ada', 'sol', 'matic', 'avax', 'dot', 'link', 'usdt', 'usdc',
                'binance', 'coinbase', 'trading', 'market', 'price', 'bull', 'bear',
                'hodl', 'satoshi', 'mining', 'wallet', 'exchange', 'token',
                'æ¯”ç‰¹å¸', 'ä»¥å¤ªåŠ', 'åŠ å¯†è´§å¸', 'åŒºå—é“¾', 'æ•°å­—è´§å¸', 'å¸', 'ä»£å¸'
            ]
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«åŠ å¯†è´§å¸å…³é”®è¯
            has_crypto_keywords = any(keyword in text_lower for keyword in crypto_keywords)
            
            if not has_crypto_keywords:
                self.logger.debug("æ¨æ–‡ä¸åŒ…å«åŠ å¯†è´§å¸å…³é”®è¯")
                return False
            
            # å¼ºåˆ¶æ’é™¤çš„æ˜æ˜¾å¹¿å‘Šå…³é”®è¯ï¼ˆæƒé‡é«˜ï¼‰
            high_spam_keywords = [
                'airdrop', 'ç©ºæŠ•', 'giveaway', 'èµ é€', 'free tokens', 'å…è´¹ä»£å¸',
                'click here', 'ç‚¹å‡»è¿™é‡Œ', 'link in bio', 'dm me', 'ç§ä¿¡æˆ‘',
                'follow for free', 'å…³æ³¨è·å¾—å…è´¹', 'join telegram', 'åŠ å…¥ç”µæŠ¥ç¾¤',
                'presale', 'é¢„å”®', 'ido', 'ico', 'é¦–å‘', 'listing soon', 'å³å°†ä¸Šå¸‚'
            ]
            
            # ä¸­ç­‰æƒé‡çš„å¹¿å‘Šå…³é”®è¯
            medium_spam_keywords = [
                'promotion', 'æ¨å¹¿', 'sponsored', 'èµåŠ©', 'partnership', 'åˆä½œ',
                'exclusive', 'ç‹¬å®¶', 'limited offer', 'é™æ—¶ä¼˜æƒ ', 'special deal', 'ç‰¹ä»·',
                'buy now', 'ç«‹å³è´­ä¹°', 'get rich', 'æš´å¯Œ', 'easy money', 'è½»æ¾èµšé’±',
                'guaranteed profit', 'ä¿è¯ç›ˆåˆ©', '100x', '1000x', 'moon mission', 'ç™»æœˆ'
            ]
            
            # ä½æƒé‡çš„å¯ç–‘å…³é”®è¯
            low_spam_keywords = [
                'pump', 'dump', 'diamond hands', 'ape in', 'lambo', 'fomo',
                'degen', 'alpha', 'gem', 'rocket', 'fire', 'bullish af'
            ]
            
            # è®¡ç®—å¹¿å‘Šå¾—åˆ†
            high_spam_score = sum(2 for keyword in high_spam_keywords if keyword in text_lower)
            medium_spam_score = sum(1 for keyword in medium_spam_keywords if keyword in text_lower)
            low_spam_score = sum(0.5 for keyword in low_spam_keywords if keyword in text_lower)
            
            total_spam_score = high_spam_score + medium_spam_score + low_spam_score
            
            # å¦‚æœåŒ…å«é«˜æƒé‡å¹¿å‘Šå…³é”®è¯ï¼Œç›´æ¥æ ‡è®°ä¸ºæ— æ•ˆ
            if high_spam_score > 0:
                self.logger.debug(f"æ¨æ–‡åŒ…å«æ˜æ˜¾å¹¿å‘Šå…³é”®è¯ï¼Œspam_score: {total_spam_score}")
                return False
            
            # å¦‚æœæ€»å¾—åˆ†è¿‡é«˜ï¼Œæ ‡è®°ä¸ºæ— æ•ˆ
            if total_spam_score >= 3:
                self.logger.debug(f"æ¨æ–‡å¹¿å‘Šç‰¹å¾å¾—åˆ†è¿‡é«˜: {total_spam_score}")
                return False
            
            # URLæ£€æŸ¥ï¼šåŒ…å«è¿‡å¤šé“¾æ¥çš„å¯èƒ½æ˜¯æ¨å¹¿
            import re
            url_count = len(re.findall(r'http[s]?://\S+', text_lower))
            if url_count > 1:  # é™ä½é˜ˆå€¼ï¼Œè¶…è¿‡1ä¸ªé“¾æ¥å°±å¯ç–‘
                self.logger.debug(f"æ¨æ–‡åŒ…å«è¿‡å¤šé“¾æ¥ ({url_count}ä¸ª)")
                return False
            
            # æ–‡æœ¬è´¨é‡æ£€æŸ¥
            if self._is_low_quality_text(text_lower):
                return False
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰ä»·å€¼çš„åˆ†æå†…å®¹
            if self._has_valuable_content(text_lower):
                self.logger.debug("æ¨æ–‡åŒ…å«æœ‰ä»·å€¼å†…å®¹ï¼Œé€šè¿‡éªŒè¯")
                return True
            
            # å¯¹äºä¸€èˆ¬å†…å®¹ï¼Œæ ¹æ®spamå¾—åˆ†å†³å®š
            if total_spam_score <= 1:
                self.logger.debug(f"æ¨æ–‡é€šè¿‡å…³é”®è¯éªŒè¯ï¼Œspam_score: {total_spam_score}")
                return True
            else:
                self.logger.debug(f"æ¨æ–‡å¯ç–‘ï¼Œspam_score: {total_spam_score}")
                return False
            
        except Exception as e:
            self.logger.error(f"å…³é”®è¯éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _has_valuable_content(self, text_lower: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰ä»·å€¼çš„åˆ†æå†…å®¹
        
        Args:
            text_lower: å°å†™æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åŒ…å«æœ‰ä»·å€¼å†…å®¹
        """
        valuable_keywords = [
            'analysis', 'åˆ†æ', 'chart', 'å›¾è¡¨', 'technical', 'æŠ€æœ¯',
            'support', 'æ”¯æ’‘', 'resistance', 'é˜»åŠ›', 'breakout', 'çªç ´',
            'pattern', 'å½¢æ€', 'trend', 'è¶‹åŠ¿', 'forecast', 'é¢„æµ‹',
            'market cap', 'å¸‚å€¼', 'volume', 'æˆäº¤é‡', 'fundamentals', 'åŸºæœ¬é¢',
            'adoption', 'é‡‡ç”¨', 'regulation', 'ç›‘ç®¡', 'news', 'æ–°é—»',
            'development', 'å¼€å‘', 'upgrade', 'å‡çº§', 'partnership', 'åˆä½œ'
        ]
        
        return any(keyword in text_lower for keyword in valuable_keywords)
    
    def _is_low_quality_text(self, text_lower: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºä½è´¨é‡æ–‡æœ¬
        
        Args:
            text_lower: å°å†™æ–‡æœ¬
            
        Returns:
            æ˜¯å¦ä¸ºä½è´¨é‡æ–‡æœ¬
        """
        # è¿‡å¤šé‡å¤å­—ç¬¦
        import re
        if re.search(r'(.)\1{4,}', text_lower):  # åŒä¸€å­—ç¬¦é‡å¤5æ¬¡ä»¥ä¸Š
            return True
        
        # è¿‡å¤šæ„Ÿå¹å·æˆ–é—®å·
        if text_lower.count('!') > 5 or text_lower.count('?') > 3:
            return True
        
        # è¿‡å¤šè¡¨æƒ…ç¬¦å·ï¼ˆç®€å•æ£€æµ‹ï¼‰
        emoji_count = len(re.findall(r'[ğŸš€ğŸ’°ğŸ’ğŸ”¥âš¡ï¸ğŸ“ˆğŸ“‰ğŸ¯ğŸŒ™ğŸ’¯ğŸ‰âœ…âŒ]', text_lower))
        if emoji_count > 8:
            return True
        
        return False
    
    def _ai_validate_content(self, text: str) -> Optional[bool]:
        """
        ä½¿ç”¨AIéªŒè¯å†…å®¹è´¨é‡
        
        Args:
            text: æ¨æ–‡å†…å®¹
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆï¼ŒNoneè¡¨ç¤ºAIåˆ†æå¤±è´¥
        """
        try:
            prompt = f"""
            è¯·åˆ†æä»¥ä¸‹æ¨æ–‡æ˜¯å¦ç¬¦åˆä»¥ä¸‹æ ‡å‡†ï¼š
            1. ä¸åŠ å¯†è´§å¸ã€åŒºå—é“¾ã€DeFiã€NFTç­‰ç›¸å…³
            2. ä¸æ˜¯æ˜æ˜¾çš„å¹¿å‘Šã€æ¨å¹¿æˆ–åƒåœ¾å†…å®¹
            3. åŒ…å«æœ‰ä»·å€¼çš„ä¿¡æ¯ã€è§‚ç‚¹æˆ–è®¨è®º
            
            æ¨æ–‡å†…å®¹: {text}
            
            è¯·åªè¿”å› true æˆ– falseï¼š
            - true: ç¬¦åˆæ ‡å‡†çš„æœ‰æ•ˆåŠ å¯†è´§å¸ç›¸å…³å†…å®¹
            - false: ä¸ç¬¦åˆæ ‡å‡†ï¼ˆéåŠ å¯†è´§å¸ç›¸å…³æˆ–æ˜æ˜¾å¹¿å‘Šï¼‰
            """
            
            response = self.chatgpt._make_request([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹è´¨é‡æ£€æŸ¥å‘˜ï¼Œä¸“é—¨è¯†åˆ«æœ‰ä»·å€¼çš„åŠ å¯†è´§å¸å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ], temperature=0.1, max_tokens=10)
            
            if response:
                result = response.strip().lower()
                return result == 'true'
            
            return None
            
        except Exception as e:
            self.logger.warning(f"AIå†…å®¹éªŒè¯å¤±è´¥: {e}")
            return None
    
    def _analyze_tweet_sentiment(self, text: str, use_ai: bool = True) -> Optional[str]:
        """
        åˆ†ææ¨æ–‡æƒ…ç»ªå€¾å‘
        
        Args:
            text: æ¨æ–‡å†…å®¹
            use_ai: æ˜¯å¦ä½¿ç”¨AIåˆ†æ
            
        Returns:
            æƒ…ç»ªå€¾å‘ï¼š'Positive'/'Negative'/'Neutral'
        """
        try:
            # æ–¹æ³•1: ä½¿ç”¨AIåˆ†æï¼ˆå¦‚æœAPIå¯ç”¨ä¸”å¯ç”¨ï¼‰
            if use_ai:
                ai_sentiment = self._ai_analyze_sentiment(text)
                if ai_sentiment:
                    return ai_sentiment
            
            # æ–¹æ³•2: åŸºäºå…³é”®è¯çš„æƒ…ç»ªåˆ†æï¼ˆé»˜è®¤æ–¹æ³•ï¼‰
            return self._keyword_analyze_sentiment(text.lower())
            
        except Exception as e:
            self.logger.error(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return 'Neutral'  # é»˜è®¤ä¸­æ€§
    
    def _keyword_analyze_sentiment(self, text_lower: str) -> str:
        """
        åŸºäºå…³é”®è¯çš„æƒ…ç»ªåˆ†æ
        
        Args:
            text_lower: å°å†™æ–‡æœ¬
            
        Returns:
            æƒ…ç»ªå€¾å‘
        """
        try:
            # ç§¯ææƒ…ç»ªå…³é”®è¯
            positive_keywords = [
                'bullish', 'moon', 'pump', 'surge', 'rally', 'breakout',
                'all-time high', 'ath', 'gains', 'profit', 'buy', 'hold',
                'diamond hands', 'hodl', 'to the moon', 'green', 'up',
                'æ¶¨', 'ç‰›å¸‚', 'çªç ´', 'æ”¶ç›Š', 'ç›ˆåˆ©', 'çœ‹å¥½', 'çœ‹æ¶¨'
            ]
            
            # æ¶ˆææƒ…ç»ªå…³é”®è¯
            negative_keywords = [
                'bearish', 'dump', 'crash', 'dip', 'sell', 'panic',
                'bear market', 'correction', 'decline', 'fall', 'drop',
                'red', 'down', 'loss', 'risk', 'warning', 'scam',
                'è·Œ', 'ç†Šå¸‚', 'ä¸‹è·Œ', 'é£é™©', 'è­¦å‘Š', 'äºæŸ', 'çœ‹ç©º'
            ]
            
            # ä¸­æ€§å…³é”®è¯ï¼ˆåˆ†æã€æŠ€æœ¯ã€è§‚å¯Ÿç­‰ï¼‰
            neutral_keywords = [
                'analysis', 'chart', 'technical', 'support', 'resistance',
                'pattern', 'trend', 'market', 'trading', 'price',
                'åˆ†æ', 'æŠ€æœ¯', 'è§‚å¯Ÿ', 'å¸‚åœº', 'ä»·æ ¼', 'èµ°åŠ¿'
            ]
            
            # è®¡ç®—æƒ…ç»ªå¾—åˆ†
            positive_score = sum(1 for keyword in positive_keywords if keyword in text_lower)
            negative_score = sum(1 for keyword in negative_keywords if keyword in text_lower)
            neutral_score = sum(1 for keyword in neutral_keywords if keyword in text_lower)
            
            # ä»·æ ¼æ•°å­—æ£€æŸ¥
            import re
            if re.search(r'(\+\d+%|up \d+%|\d+% gain)', text_lower):
                positive_score += 2
            elif re.search(r'(-\d+%|down \d+%|\d+% loss)', text_lower):
                negative_score += 2
            
            # å†³å®šæƒ…ç»ªå€¾å‘
            if positive_score > negative_score and positive_score > 0:
                return 'Positive'
            elif negative_score > positive_score and negative_score > 0:
                return 'Negative'
            else:
                return 'Neutral'
            
        except Exception as e:
            self.logger.error(f"å…³é”®è¯æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return 'Neutral'
    
    def _ai_analyze_sentiment(self, text: str) -> Optional[str]:
        """
        ä½¿ç”¨AIåˆ†ææƒ…ç»ª
        
        Args:
            text: æ¨æ–‡å†…å®¹
            
        Returns:
            æƒ…ç»ªå€¾å‘æˆ–None
        """
        try:
            sentiment_result = self.chatgpt.analyze_sentiment(text)
            
            if sentiment_result and 'sentiment' in sentiment_result:
                ai_sentiment = sentiment_result['sentiment'].lower()
                
                # æ˜ å°„åˆ°æ ‡å‡†æ ¼å¼
                if ai_sentiment == 'positive':
                    return 'Positive'
                elif ai_sentiment == 'negative':
                    return 'Negative'
                else:
                    return 'Neutral'
            
            return None
            
        except Exception as e:
            self.logger.warning(f"AIæƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return None
    
    def _extract_kol_id_from_user_data(self, tweet: Tweet, 
                                      user_data_map: Dict[str, Dict[str, Any]]) -> Optional[str]:
        """
        ä»æ¨æ–‡å¯¹åº”çš„ç”¨æˆ·æ•°æ®ä¸­æå–kol_idï¼ˆå³ç”¨æˆ·çš„id_strï¼‰
        
        Args:
            tweet: æ¨æ–‡å¯¹è±¡
            user_data_map: ç”¨æˆ·æ•°æ®æ˜ å°„ {tweet_id: user_data}
            
        Returns:
            ç”¨æˆ·IDï¼ˆä½œä¸ºkol_idï¼‰
        """
        try:
            # æ–¹æ³•1: æ ¹æ®æ¨æ–‡IDæ‰¾åˆ°å¯¹åº”çš„ç”¨æˆ·æ•°æ®
            # user_data_mapåº”è¯¥æ˜¯ {tweet_id: user_data} çš„æ˜ å°„
            user_data = user_data_map.get(tweet.id_str)
            if user_data:
                user_id_str = user_data.get('id_str')
                if user_id_str:
                    self.logger.debug(f"æ¨æ–‡ {tweet.id_str} æ‰¾åˆ°å¯¹åº”ç”¨æˆ·: {user_id_str}")
                    return user_id_str
            
            # æ–¹æ³•2: å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„ç”¨æˆ·æ•°æ®ï¼Œéå†æ‰€æœ‰ç”¨æˆ·æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
            # ä½†è¿™ç§æ–¹æ³•å®¹æ˜“å¯¼è‡´é”™è¯¯çš„æ˜ å°„
            if not user_data_map:
                self.logger.warning(f"æ¨æ–‡ {tweet.id_str} çš„ç”¨æˆ·æ•°æ®æ˜ å°„ä¸ºç©º")
                return None
            
            # å¦‚æœuser_data_mapä¸æ˜¯æŒ‰tweet_idç»„ç»‡çš„ï¼Œå°è¯•å…¶ä»–æ–¹å¼
            # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‰user_idç»„ç»‡çš„æ˜ å°„
            for key, data in user_data_map.items():
                if isinstance(data, dict) and data.get('id_str'):
                    # è¿™å¯èƒ½æ˜¯ä¸€ä¸ªç”¨æˆ·æ•°æ®ï¼Œä½†æˆ‘ä»¬éœ€è¦æ‰¾åˆ°æ¨æ–‡å¯¹åº”çš„ç”¨æˆ·
                    # ç”±äºæ²¡æœ‰ç›´æ¥çš„æ˜ å°„å…³ç³»ï¼Œæˆ‘ä»¬æ— æ³•ç¡®å®šå“ªä¸ªç”¨æˆ·å‘äº†è¿™æ¡æ¨æ–‡
                    pass
            
            self.logger.warning(f"æ¨æ–‡ {tweet.id_str} æ— æ³•åœ¨ç”¨æˆ·æ•°æ®æ˜ å°„ä¸­æ‰¾åˆ°å¯¹åº”çš„ç”¨æˆ·")
            return None
            
        except Exception as e:
            self.logger.error(f"æå–ç”¨æˆ·IDå¤±è´¥ {tweet.id_str}: {e}")
            return None
    
    def _generate_tweet_url(self, tweet: Tweet) -> Optional[str]:
        """
        ç”Ÿæˆæ¨æ–‡URL
        
        Args:
            tweet: æ¨æ–‡å¯¹è±¡
            
        Returns:
            æ¨æ–‡URL
        """
        try:
            if not tweet.id_str:
                return None
            
            # ä½¿ç”¨å›ºå®šçš„ç”¨æˆ·åç”ŸæˆURLï¼Œæ ¼å¼ï¼šhttps://x.com/aixbt_agent/status/{id_str}
            base_url = "https://x.com/aixbt_agent/status/"
            tweet_url = f"{base_url}{tweet.id_str}"
            
            self.logger.info(f"ä¸ºæ¨æ–‡ {tweet.id_str} ç”ŸæˆURL: {tweet_url}")
            return tweet_url
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ¨æ–‡URLå¤±è´¥ {tweet.id_str}: {e}")
            return None
    
    
    def should_process_in_crawler_flow(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥åœ¨çˆ¬è™«æµç¨‹ä¸­å¤„ç†è¯é¢˜æ•°æ®ç”Ÿæˆ
        
        Returns:
            æ˜¯å¦åº”è¯¥åœ¨çˆ¬è™«æµç¨‹ä¸­å¤„ç†
        """
        # åˆ†æï¼šè¯é¢˜æ•°æ®ç”Ÿæˆåº”è¯¥åœ¨çˆ¬è™«æµç¨‹ä¸­å®Œæˆï¼ŒåŸå› å¦‚ä¸‹ï¼š
        # 1. æ•°æ®ä¸€è‡´æ€§ï¼šæ¨æ–‡å’Œè¯é¢˜æ•°æ®éœ€è¦ä¿æŒå…³è”ä¸€è‡´æ€§
        # 2. å®æ—¶æ€§ï¼šè¯é¢˜è¯†åˆ«éœ€è¦åœ¨æ¨æ–‡å…¥åº“æ—¶å°±å®Œæˆï¼Œé¿å…å»¶è¿Ÿ
        # 3. æ€§èƒ½ï¼šé¿å…åç»­æ‰¹é‡å¤„ç†å¸¦æ¥çš„é¢å¤–å¼€é”€
        # 4. ç®€åŒ–æ¶æ„ï¼šç»Ÿä¸€åœ¨ä¸€ä¸ªæµç¨‹ä¸­å¤„ç†ï¼Œå‡å°‘ç³»ç»Ÿå¤æ‚åº¦
        return True
    
    def _classify_and_set_ids(self, tweet: Tweet):
        """
        ä½¿ç”¨æ™ºèƒ½åˆ†ç±»å™¨å¯¹æ¨æ–‡è¿›è¡Œåˆ†ç±»ï¼Œå¹¶è®¾ç½®project_idå’Œtopic_id
        
        Args:
            tweet: æ¨æ–‡å¯¹è±¡
            
        Returns:
            ClassificationResult: åˆ†ç±»ç»“æœ
        """
        try:
            # ä½¿ç”¨æ™ºèƒ½åˆ†ç±»å™¨è¿›è¡Œåˆ†ç±»
            classification_result = smart_classifier.classify_tweet(tweet)
            
            if classification_result.content_type == 'unknown':
                self.logger.debug(f"æ¨æ–‡ {tweet.id_str} æ— æ³•åˆ†ç±»: {classification_result.reason}")
            elif classification_result.content_type == 'project':
                self.logger.info(f"æ¨æ–‡ {tweet.id_str} è¯†åˆ«ä¸ºé¡¹ç›®: {classification_result.entity_name} " +
                               f"(project_id: {classification_result.project_id}, " +
                               f"æ–°åˆ›å»º: {classification_result.is_new_created})")
            elif classification_result.content_type == 'topic':
                self.logger.info(f"æ¨æ–‡ {tweet.id_str} è¯†åˆ«ä¸ºè¯é¢˜: {classification_result.entity_name} " +
                               f"(topic_id: {classification_result.topic_id}, " +
                               f"æ–°åˆ›å»º: {classification_result.is_new_created})")
            
            return classification_result
            
        except Exception as e:
            self.logger.error(f"åˆ†ç±»æ¨æ–‡å¤±è´¥ {tweet.id_str}: {e}")
            # è¿”å›ç©ºçš„åˆ†ç±»ç»“æœ
            from .smart_classifier import ClassificationResult
            return ClassificationResult(content_type='unknown', reason=f"åˆ†ç±»å‡ºé”™: {str(e)}")


# å…¨å±€æ¨æ–‡å¢å¼ºå™¨å®ä¾‹
tweet_enricher = TweetEnricher()
